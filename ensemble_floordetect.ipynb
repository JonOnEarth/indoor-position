{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Example With Boston Dataset: Standardized \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "path = 'C:/Users/mys12/Desktop/northeastern/summer2018/data_Robust_Fingerprinting-master/DISTRIBUTED_OPENSOURCE/FINGERPRINTING_DB'\n",
    "\n",
    "test_rss = pd.read_csv(path + '/Training_rss_21Aug17.csv', header = 0)\n",
    "test_coord = pd.read_csv(path + '/Training_coordinates_21Aug17.csv', header = 0)\n",
    "test_rss = test_rss.replace(100, 0)\n",
    "\n",
    "train_rss = pd.read_csv(path + '/Test_rss_21Aug17.csv', header = 0)\n",
    "train_coord = pd.read_csv(path + '/Test_coordinates_21Aug17.csv', header = 0)\n",
    "train_rss = train_rss.replace(100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels:  (array(['0.0', '11.1', '14.8', '3.7', '7.4'], dtype=object), array([1264,  699,  109, 1108,  770], dtype=int64))\n",
      "test_labels:  (array(['0.0', '11.1', '14.8', '3.7', '7.4'], dtype=object), array([226, 118,  17, 197, 138], dtype=int64))\n",
      "(696, 992)\n",
      "(3950, 992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "train_r = train_rss.values\n",
    "train_ch = train_coord.iloc[:,-1]\n",
    "building_floors_str = train_ch.map(str)  #convert all the building floors to strings\n",
    "print(\"train_labels: \", np.unique(building_floors_str, return_counts=True))\n",
    "\n",
    "train_labels = np.asarray(building_floors_str)\n",
    "#convert labels to categorical variables, dummy_labels has type 'pandas.core.frame.DataFrame'\n",
    "dummy_label = pd.get_dummies(train_labels)\n",
    "train_labels = np.asarray(dummy_label)\n",
    "\n",
    "normalizer = preprocessing.Normalizer().fit(np.asarray(train_r))\n",
    "train_r_features = normalizer.transform(np.asarray(train_r))\n",
    "\n",
    "# test\n",
    "test_r = test_rss.values\n",
    "test_ch = test_coord.ix[:,-1]\n",
    "test_labels = np.asarray(test_ch.map(str))\n",
    "print(\"test_labels: \", np.unique(test_labels, return_counts=True))\n",
    "\n",
    "test_labels = np.asarray(pd.get_dummies(test_labels))\n",
    "\n",
    "#Scale transforms data to center to the mean and component wise scale to unit variance\n",
    "test_r_features = normalizer.transform(np.asarray(test_r))\n",
    "print(test_r_features.shape)\n",
    "\n",
    "\n",
    "print(train_r_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random subsample from the dataset with replacement \n",
    "from random import seed \n",
    "from random import randrange\n",
    "\n",
    "def subsample(x,y, ratio=0.5): \n",
    "    sample_x = list() \n",
    "    sample_y = list()\n",
    "    n_sample = round(len(x) * ratio) \n",
    "    while len(sample_x) < n_sample: \n",
    "        index = randrange(len(x)) \n",
    "        sample_x.append(x[index]) \n",
    "        sample_y.append(y[index])\n",
    "    sample_x = np.array(sample_x)\n",
    "    sample_y = np.array(sample_y)\n",
    "    return sample_x, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1_x, train1_y = subsample(train_r_features, train_labels)\n",
    "# train2_x, train2_y = subsample(train_r_features, train_labels)\n",
    "# train3_x, train3_y = subsample(train_r_features, train_labels)\n",
    "# train4_x, train4_y = subsample(train_r_features, train_labels)\n",
    "# train5_x, train5_y = subsample(train_r_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "batch_size = 64\n",
    "input_size = 992\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_size, activation='tanh', bias=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='tanh', bias=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax', bias=True))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.predict(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(l1,l2):\n",
    "    a=0\n",
    "    for i in l1, j in l2:\n",
    "        if i == j:\n",
    "            a=a+1\n",
    "    return a / len(l1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val(train_Xx, train_Yy):\n",
    "    train_x, val_x, train_y, val_y = train_test_split(train_Xx, train_Yy, test_size=0.2)\n",
    "    return train_x, val_x, train_y, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=992, activation=\"tanh\", use_bias=True)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"tanh\", use_bias=True)`\n",
      "  \"\"\"\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"softmax\", use_bias=True)`\n",
      "  import sys\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1580 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1580/1580 [==============================] - 2s - loss: 1.0618 - acc: 0.6209 - val_loss: 0.6637 - val_acc: 0.7443\n",
      "Epoch 2/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.5717 - acc: 0.7715 - val_loss: 0.4468 - val_acc: 0.8329\n",
      "Epoch 3/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.4028 - acc: 0.8475 - val_loss: 0.3347 - val_acc: 0.8937\n",
      "Epoch 4/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.3078 - acc: 0.8899 - val_loss: 0.2813 - val_acc: 0.9038\n",
      "Epoch 5/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2576 - acc: 0.9051 - val_loss: 0.2681 - val_acc: 0.9215\n",
      "Epoch 6/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2165 - acc: 0.9247 - val_loss: 0.2619 - val_acc: 0.9114\n",
      "Epoch 7/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1921 - acc: 0.9342 - val_loss: 0.2317 - val_acc: 0.9190\n",
      "Epoch 8/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1701 - acc: 0.9462 - val_loss: 0.2297 - val_acc: 0.9241\n",
      "Epoch 9/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1632 - acc: 0.9443 - val_loss: 0.2225 - val_acc: 0.9316\n",
      "Epoch 10/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1422 - acc: 0.9513 - val_loss: 0.2214 - val_acc: 0.9342\n",
      "Epoch 11/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1346 - acc: 0.9525 - val_loss: 0.2245 - val_acc: 0.9266\n",
      "Epoch 12/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1248 - acc: 0.9563 - val_loss: 0.2191 - val_acc: 0.9367\n",
      "Epoch 13/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1082 - acc: 0.9665 - val_loss: 0.2042 - val_acc: 0.9316\n",
      "Epoch 14/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0997 - acc: 0.9677 - val_loss: 0.1997 - val_acc: 0.9367\n",
      "Epoch 15/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1010 - acc: 0.9671 - val_loss: 0.2119 - val_acc: 0.9215\n",
      "Epoch 16/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0970 - acc: 0.9671 - val_loss: 0.1952 - val_acc: 0.9418\n",
      "Epoch 17/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0945 - acc: 0.9703 - val_loss: 0.2167 - val_acc: 0.9291\n",
      "Epoch 18/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0898 - acc: 0.9696 - val_loss: 0.2039 - val_acc: 0.9367\n",
      "Epoch 19/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0787 - acc: 0.9722 - val_loss: 0.2155 - val_acc: 0.9367\n",
      "Epoch 20/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0844 - acc: 0.9734 - val_loss: 0.2088 - val_acc: 0.9266\n",
      "Epoch 21/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0833 - acc: 0.9772 - val_loss: 0.2168 - val_acc: 0.9291\n",
      "Epoch 22/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0733 - acc: 0.9759 - val_loss: 0.2002 - val_acc: 0.9443\n",
      "Epoch 23/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0737 - acc: 0.9753 - val_loss: 0.2116 - val_acc: 0.9316\n",
      "Epoch 24/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0632 - acc: 0.9804 - val_loss: 0.2135 - val_acc: 0.9392\n",
      "Epoch 25/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0684 - acc: 0.9810 - val_loss: 0.2196 - val_acc: 0.9215\n",
      "Epoch 26/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0613 - acc: 0.9810 - val_loss: 0.2217 - val_acc: 0.9367\n",
      "Epoch 27/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0556 - acc: 0.9804 - val_loss: 0.2282 - val_acc: 0.9367\n",
      "Epoch 28/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0579 - acc: 0.9823 - val_loss: 0.2283 - val_acc: 0.9342\n",
      "Epoch 29/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0628 - acc: 0.9778 - val_loss: 0.2350 - val_acc: 0.9392\n",
      "Epoch 30/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0527 - acc: 0.9854 - val_loss: 0.2368 - val_acc: 0.9266\n",
      "Epoch 31/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0497 - acc: 0.9867 - val_loss: 0.2266 - val_acc: 0.9342\n",
      "Epoch 32/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0535 - acc: 0.9816 - val_loss: 0.2475 - val_acc: 0.9316\n",
      "Epoch 33/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0464 - acc: 0.9880 - val_loss: 0.2710 - val_acc: 0.9241\n",
      "Epoch 34/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0468 - acc: 0.9829 - val_loss: 0.2569 - val_acc: 0.9316\n",
      "Epoch 35/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0445 - acc: 0.9829 - val_loss: 0.2444 - val_acc: 0.9316\n",
      "Epoch 36/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0467 - acc: 0.9842 - val_loss: 0.2638 - val_acc: 0.9316\n",
      "Epoch 37/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0445 - acc: 0.9848 - val_loss: 0.2629 - val_acc: 0.9316\n",
      "Epoch 38/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0409 - acc: 0.9911 - val_loss: 0.2659 - val_acc: 0.9316\n",
      "Epoch 39/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0460 - acc: 0.9848 - val_loss: 0.2704 - val_acc: 0.9266\n",
      "Epoch 40/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0384 - acc: 0.9880 - val_loss: 0.2674 - val_acc: 0.9241\n",
      "Epoch 41/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0353 - acc: 0.9886 - val_loss: 0.2798 - val_acc: 0.9215\n",
      "Epoch 42/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0330 - acc: 0.9892 - val_loss: 0.2903 - val_acc: 0.9241\n",
      "Epoch 43/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0392 - acc: 0.9867 - val_loss: 0.2649 - val_acc: 0.9291\n",
      "Epoch 44/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0322 - acc: 0.9880 - val_loss: 0.2970 - val_acc: 0.9291\n",
      "Epoch 45/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0361 - acc: 0.9854 - val_loss: 0.2803 - val_acc: 0.9241\n",
      "Epoch 46/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0329 - acc: 0.9899 - val_loss: 0.3198 - val_acc: 0.9266\n",
      "Epoch 47/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0325 - acc: 0.9886 - val_loss: 0.3145 - val_acc: 0.9316\n",
      "Epoch 48/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0342 - acc: 0.9880 - val_loss: 0.3015 - val_acc: 0.9266\n",
      "Epoch 49/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0354 - acc: 0.9880 - val_loss: 0.2988 - val_acc: 0.9241\n",
      "Epoch 50/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0344 - acc: 0.9886 - val_loss: 0.3061 - val_acc: 0.9291\n",
      "Epoch 51/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0346 - acc: 0.9899 - val_loss: 0.2982 - val_acc: 0.9291\n",
      "Epoch 52/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0245 - acc: 0.9930 - val_loss: 0.3207 - val_acc: 0.9266\n",
      "Epoch 53/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0253 - acc: 0.9905 - val_loss: 0.3210 - val_acc: 0.9316\n",
      "Epoch 54/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0313 - acc: 0.9899 - val_loss: 0.3226 - val_acc: 0.9316\n",
      "Epoch 55/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0246 - acc: 0.9918 - val_loss: 0.3343 - val_acc: 0.9316\n",
      "Epoch 56/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0307 - acc: 0.9880 - val_loss: 0.3444 - val_acc: 0.9316\n",
      "Epoch 57/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0286 - acc: 0.9918 - val_loss: 0.3261 - val_acc: 0.9266\n",
      "Epoch 58/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0269 - acc: 0.9911 - val_loss: 0.3359 - val_acc: 0.9342\n",
      "Epoch 59/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0278 - acc: 0.9918 - val_loss: 0.3357 - val_acc: 0.9316\n",
      "Epoch 60/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0248 - acc: 0.9937 - val_loss: 0.3514 - val_acc: 0.9291\n",
      "Epoch 61/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0216 - acc: 0.9937 - val_loss: 0.3540 - val_acc: 0.9266\n",
      "Epoch 62/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0237 - acc: 0.9911 - val_loss: 0.3628 - val_acc: 0.9266\n",
      "Epoch 63/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0305 - acc: 0.9886 - val_loss: 0.3497 - val_acc: 0.9291\n",
      "Epoch 64/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0302 - acc: 0.9892 - val_loss: 0.3596 - val_acc: 0.9266\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0293 - acc: 0.9892 - val_loss: 0.3765 - val_acc: 0.9266\n",
      "Epoch 66/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0206 - acc: 0.9905 - val_loss: 0.3754 - val_acc: 0.9266\n",
      "Epoch 67/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0154 - acc: 0.9956 - val_loss: 0.3712 - val_acc: 0.9266\n",
      "Epoch 68/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0190 - acc: 0.9930 - val_loss: 0.3813 - val_acc: 0.9266\n",
      "Epoch 69/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0184 - acc: 0.9962 - val_loss: 0.3797 - val_acc: 0.9241\n",
      "Epoch 70/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0195 - acc: 0.9949 - val_loss: 0.3930 - val_acc: 0.9266\n",
      "Epoch 71/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0156 - acc: 0.9943 - val_loss: 0.3681 - val_acc: 0.9266\n",
      "Epoch 72/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0298 - acc: 0.9905 - val_loss: 0.3678 - val_acc: 0.9291\n",
      "Epoch 73/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0205 - acc: 0.9930 - val_loss: 0.3783 - val_acc: 0.9266\n",
      "Epoch 74/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0241 - acc: 0.9937 - val_loss: 0.3762 - val_acc: 0.9266\n",
      "Epoch 75/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0167 - acc: 0.9943 - val_loss: 0.3835 - val_acc: 0.9241\n",
      "Epoch 76/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0179 - acc: 0.9937 - val_loss: 0.3543 - val_acc: 0.9241\n",
      "Epoch 77/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0168 - acc: 0.9949 - val_loss: 0.3968 - val_acc: 0.9241\n",
      "Epoch 78/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0223 - acc: 0.9911 - val_loss: 0.3692 - val_acc: 0.9241\n",
      "Epoch 79/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0254 - acc: 0.9905 - val_loss: 0.4131 - val_acc: 0.9215\n",
      "Epoch 80/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0199 - acc: 0.9918 - val_loss: 0.4109 - val_acc: 0.9291\n",
      "Epoch 81/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0159 - acc: 0.9956 - val_loss: 0.4134 - val_acc: 0.9291\n",
      "Epoch 82/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0113 - acc: 0.9962 - val_loss: 0.3827 - val_acc: 0.9316\n",
      "Epoch 83/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0146 - acc: 0.9956 - val_loss: 0.3822 - val_acc: 0.9316\n",
      "Epoch 84/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0161 - acc: 0.9943 - val_loss: 0.3952 - val_acc: 0.9342\n",
      "Epoch 85/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0226 - acc: 0.9949 - val_loss: 0.3999 - val_acc: 0.9266\n",
      "Epoch 86/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0291 - acc: 0.9905 - val_loss: 0.3826 - val_acc: 0.9316\n",
      "Epoch 87/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0253 - acc: 0.9930 - val_loss: 0.4043 - val_acc: 0.9291\n",
      "Epoch 88/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0181 - acc: 0.9924 - val_loss: 0.3973 - val_acc: 0.9291\n",
      "Epoch 89/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0178 - acc: 0.9943 - val_loss: 0.3999 - val_acc: 0.9316\n",
      "Epoch 90/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0227 - acc: 0.9924 - val_loss: 0.3709 - val_acc: 0.9367\n",
      "Epoch 91/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0301 - acc: 0.9867 - val_loss: 0.4747 - val_acc: 0.9241\n",
      "Epoch 92/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0281 - acc: 0.9905 - val_loss: 0.4046 - val_acc: 0.9241\n",
      "Epoch 93/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0162 - acc: 0.9943 - val_loss: 0.4002 - val_acc: 0.9291\n",
      "Epoch 94/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0178 - acc: 0.9962 - val_loss: 0.4114 - val_acc: 0.9316\n",
      "Epoch 95/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0143 - acc: 0.9937 - val_loss: 0.4189 - val_acc: 0.9291\n",
      "Epoch 96/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0165 - acc: 0.9943 - val_loss: 0.4194 - val_acc: 0.9291\n",
      "Epoch 97/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0146 - acc: 0.9949 - val_loss: 0.4062 - val_acc: 0.9266\n",
      "Epoch 98/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0138 - acc: 0.9968 - val_loss: 0.4316 - val_acc: 0.9266\n",
      "Epoch 99/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0177 - acc: 0.9924 - val_loss: 0.4508 - val_acc: 0.9291\n",
      "Epoch 100/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0133 - acc: 0.9968 - val_loss: 0.4635 - val_acc: 0.9316\n",
      " 32/696 [>.............................] - ETA: 6sfor subsample 0, its accuarcy is 0.8779\n",
      "Train on 1580 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1580/1580 [==============================] - 0s - loss: 1.0703 - acc: 0.6114 - val_loss: 0.6709 - val_acc: 0.7975\n",
      "Epoch 2/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.5913 - acc: 0.7810 - val_loss: 0.4316 - val_acc: 0.8532\n",
      "Epoch 3/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.4173 - acc: 0.8544 - val_loss: 0.3252 - val_acc: 0.8759\n",
      "Epoch 4/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.3159 - acc: 0.8981 - val_loss: 0.2742 - val_acc: 0.9089\n",
      "Epoch 5/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2630 - acc: 0.9171 - val_loss: 0.2481 - val_acc: 0.9165\n",
      "Epoch 6/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2201 - acc: 0.9278 - val_loss: 0.2307 - val_acc: 0.9316\n",
      "Epoch 7/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1995 - acc: 0.9342 - val_loss: 0.2280 - val_acc: 0.9316\n",
      "Epoch 8/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1760 - acc: 0.9424 - val_loss: 0.2194 - val_acc: 0.9266\n",
      "Epoch 9/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1530 - acc: 0.9481 - val_loss: 0.2285 - val_acc: 0.9241\n",
      "Epoch 10/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1406 - acc: 0.9576 - val_loss: 0.2146 - val_acc: 0.9418\n",
      "Epoch 11/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1362 - acc: 0.9513 - val_loss: 0.2023 - val_acc: 0.9392\n",
      "Epoch 12/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1198 - acc: 0.9627 - val_loss: 0.2073 - val_acc: 0.9443\n",
      "Epoch 13/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1149 - acc: 0.9639 - val_loss: 0.2067 - val_acc: 0.9443\n",
      "Epoch 14/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0998 - acc: 0.9690 - val_loss: 0.2007 - val_acc: 0.9519\n",
      "Epoch 15/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1039 - acc: 0.9633 - val_loss: 0.2122 - val_acc: 0.9519\n",
      "Epoch 16/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0950 - acc: 0.9696 - val_loss: 0.2153 - val_acc: 0.9544\n",
      "Epoch 17/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0838 - acc: 0.9741 - val_loss: 0.2341 - val_acc: 0.9443\n",
      "Epoch 18/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0828 - acc: 0.9728 - val_loss: 0.2279 - val_acc: 0.9316\n",
      "Epoch 19/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0809 - acc: 0.9734 - val_loss: 0.2404 - val_acc: 0.9342\n",
      "Epoch 20/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0736 - acc: 0.9709 - val_loss: 0.2530 - val_acc: 0.9392\n",
      "Epoch 21/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0698 - acc: 0.9753 - val_loss: 0.2298 - val_acc: 0.9367\n",
      "Epoch 22/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0782 - acc: 0.9696 - val_loss: 0.2321 - val_acc: 0.9443\n",
      "Epoch 23/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0639 - acc: 0.9835 - val_loss: 0.2499 - val_acc: 0.9316\n",
      "Epoch 24/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0637 - acc: 0.9785 - val_loss: 0.2443 - val_acc: 0.9494\n",
      "Epoch 25/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0680 - acc: 0.9728 - val_loss: 0.2544 - val_acc: 0.9392\n",
      "Epoch 26/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0593 - acc: 0.9759 - val_loss: 0.2626 - val_acc: 0.9367\n",
      "Epoch 27/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0578 - acc: 0.9810 - val_loss: 0.2683 - val_acc: 0.9367\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0622 - acc: 0.9753 - val_loss: 0.2799 - val_acc: 0.9316\n",
      "Epoch 29/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0499 - acc: 0.9829 - val_loss: 0.2843 - val_acc: 0.9266\n",
      "Epoch 30/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0517 - acc: 0.9816 - val_loss: 0.3045 - val_acc: 0.9241\n",
      "Epoch 31/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0522 - acc: 0.9816 - val_loss: 0.2922 - val_acc: 0.9291\n",
      "Epoch 32/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0484 - acc: 0.9867 - val_loss: 0.2869 - val_acc: 0.9316\n",
      "Epoch 33/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0429 - acc: 0.9886 - val_loss: 0.3098 - val_acc: 0.9266\n",
      "Epoch 34/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0470 - acc: 0.9835 - val_loss: 0.3361 - val_acc: 0.9215\n",
      "Epoch 35/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0459 - acc: 0.9880 - val_loss: 0.3002 - val_acc: 0.9342\n",
      "Epoch 36/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0407 - acc: 0.9861 - val_loss: 0.3127 - val_acc: 0.9316\n",
      "Epoch 37/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.3429 - val_acc: 0.9266\n",
      "Epoch 38/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0420 - acc: 0.9848 - val_loss: 0.3229 - val_acc: 0.9165\n",
      "Epoch 39/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0376 - acc: 0.9867 - val_loss: 0.3548 - val_acc: 0.9215\n",
      "Epoch 40/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0401 - acc: 0.9880 - val_loss: 0.3392 - val_acc: 0.9215\n",
      "Epoch 41/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0374 - acc: 0.9867 - val_loss: 0.3434 - val_acc: 0.9316\n",
      "Epoch 42/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0301 - acc: 0.9905 - val_loss: 0.3486 - val_acc: 0.9241\n",
      "Epoch 43/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0319 - acc: 0.9892 - val_loss: 0.3503 - val_acc: 0.9165\n",
      "Epoch 44/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0334 - acc: 0.9911 - val_loss: 0.3403 - val_acc: 0.9241\n",
      "Epoch 45/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0322 - acc: 0.9911 - val_loss: 0.3652 - val_acc: 0.9241\n",
      "Epoch 46/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0402 - acc: 0.9854 - val_loss: 0.3856 - val_acc: 0.9165\n",
      "Epoch 47/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0403 - acc: 0.9848 - val_loss: 0.3631 - val_acc: 0.9241\n",
      "Epoch 48/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0388 - acc: 0.9873 - val_loss: 0.3551 - val_acc: 0.9316\n",
      "Epoch 49/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0304 - acc: 0.9899 - val_loss: 0.3805 - val_acc: 0.9266\n",
      "Epoch 50/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0355 - acc: 0.9892 - val_loss: 0.3636 - val_acc: 0.9241\n",
      "Epoch 51/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0338 - acc: 0.9886 - val_loss: 0.3742 - val_acc: 0.9215\n",
      "Epoch 52/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0350 - acc: 0.9861 - val_loss: 0.4057 - val_acc: 0.9139\n",
      "Epoch 53/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0260 - acc: 0.9930 - val_loss: 0.3878 - val_acc: 0.92910.9\n",
      "Epoch 54/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0252 - acc: 0.9911 - val_loss: 0.3609 - val_acc: 0.9215\n",
      "Epoch 55/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0243 - acc: 0.9911 - val_loss: 0.3984 - val_acc: 0.9266\n",
      "Epoch 56/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0366 - acc: 0.9899 - val_loss: 0.4185 - val_acc: 0.9139\n",
      "Epoch 57/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0243 - acc: 0.9911 - val_loss: 0.4162 - val_acc: 0.9266\n",
      "Epoch 58/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0278 - acc: 0.9911 - val_loss: 0.3878 - val_acc: 0.9165\n",
      "Epoch 59/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0321 - acc: 0.9873 - val_loss: 0.4313 - val_acc: 0.9190\n",
      "Epoch 60/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0262 - acc: 0.9899 - val_loss: 0.4098 - val_acc: 0.9241\n",
      "Epoch 61/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0170 - acc: 0.9949 - val_loss: 0.4505 - val_acc: 0.9190\n",
      "Epoch 62/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0225 - acc: 0.9899 - val_loss: 0.4356 - val_acc: 0.9165\n",
      "Epoch 63/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0359 - acc: 0.9892 - val_loss: 0.4592 - val_acc: 0.9190\n",
      "Epoch 64/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0185 - acc: 0.9949 - val_loss: 0.4184 - val_acc: 0.9241\n",
      "Epoch 65/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0241 - acc: 0.9918 - val_loss: 0.4249 - val_acc: 0.9190\n",
      "Epoch 66/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0262 - acc: 0.9899 - val_loss: 0.5055 - val_acc: 0.9190\n",
      "Epoch 67/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0356 - acc: 0.9873 - val_loss: 0.4371 - val_acc: 0.9165\n",
      "Epoch 68/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0307 - acc: 0.9905 - val_loss: 0.4650 - val_acc: 0.9165\n",
      "Epoch 69/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0234 - acc: 0.9918 - val_loss: 0.4364 - val_acc: 0.9190\n",
      "Epoch 70/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0260 - acc: 0.9924 - val_loss: 0.4500 - val_acc: 0.9190\n",
      "Epoch 71/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0187 - acc: 0.9918 - val_loss: 0.4487 - val_acc: 0.9063\n",
      "Epoch 72/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0254 - acc: 0.9886 - val_loss: 0.4495 - val_acc: 0.9165\n",
      "Epoch 73/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0171 - acc: 0.9937 - val_loss: 0.4308 - val_acc: 0.9190\n",
      "Epoch 74/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0135 - acc: 0.9968 - val_loss: 0.4966 - val_acc: 0.9190\n",
      "Epoch 75/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0219 - acc: 0.9930 - val_loss: 0.4757 - val_acc: 0.9215\n",
      "Epoch 76/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0158 - acc: 0.9937 - val_loss: 0.4819 - val_acc: 0.9139\n",
      "Epoch 77/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0140 - acc: 0.9956 - val_loss: 0.4530 - val_acc: 0.9114\n",
      "Epoch 78/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0124 - acc: 0.9968 - val_loss: 0.4604 - val_acc: 0.9165\n",
      "Epoch 79/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0152 - acc: 0.9962 - val_loss: 0.4979 - val_acc: 0.9114\n",
      "Epoch 80/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0127 - acc: 0.9949 - val_loss: 0.4786 - val_acc: 0.9139\n",
      "Epoch 81/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0181 - acc: 0.9930 - val_loss: 0.5300 - val_acc: 0.9089\n",
      "Epoch 82/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0176 - acc: 0.9949 - val_loss: 0.5365 - val_acc: 0.9089\n",
      "Epoch 83/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0198 - acc: 0.9937 - val_loss: 0.5306 - val_acc: 0.9063\n",
      "Epoch 84/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0149 - acc: 0.9956 - val_loss: 0.5534 - val_acc: 0.9089\n",
      "Epoch 85/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0094 - acc: 0.9981 - val_loss: 0.4978 - val_acc: 0.9114\n",
      "Epoch 86/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0108 - acc: 0.9968 - val_loss: 0.4971 - val_acc: 0.9114\n",
      "Epoch 87/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0113 - acc: 0.9962 - val_loss: 0.5108 - val_acc: 0.9089\n",
      "Epoch 88/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0126 - acc: 0.9956 - val_loss: 0.5362 - val_acc: 0.9089\n",
      "Epoch 89/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0159 - acc: 0.9949 - val_loss: 0.5255 - val_acc: 0.9063\n",
      "Epoch 90/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0290 - acc: 0.9886 - val_loss: 0.5865 - val_acc: 0.9063\n",
      "Epoch 91/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0189 - acc: 0.9937 - val_loss: 0.5665 - val_acc: 0.9114\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0294 - acc: 0.9905 - val_loss: 0.6170 - val_acc: 0.9038\n",
      "Epoch 93/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0203 - acc: 0.9937 - val_loss: 0.5398 - val_acc: 0.9114\n",
      "Epoch 94/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0154 - acc: 0.9949 - val_loss: 0.5631 - val_acc: 0.9089\n",
      "Epoch 95/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0184 - acc: 0.9943 - val_loss: 0.5768 - val_acc: 0.8937\n",
      "Epoch 96/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0171 - acc: 0.9937 - val_loss: 0.5050 - val_acc: 0.9139\n",
      "Epoch 97/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0160 - acc: 0.9956 - val_loss: 0.5381 - val_acc: 0.9139\n",
      "Epoch 98/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0157 - acc: 0.9943 - val_loss: 0.5779 - val_acc: 0.9089\n",
      "Epoch 99/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0185 - acc: 0.9937 - val_loss: 0.5515 - val_acc: 0.9038\n",
      "Epoch 100/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0142 - acc: 0.9956 - val_loss: 0.5841 - val_acc: 0.9165\n",
      " 32/696 [>.............................] - ETA: 6sfor subsample 1, its accuarcy is 0.8635\n",
      "Train on 1580 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1580/1580 [==============================] - 0s - loss: 1.0970 - acc: 0.6310 - val_loss: 0.6875 - val_acc: 0.8076\n",
      "Epoch 2/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.5570 - acc: 0.7994 - val_loss: 0.4071 - val_acc: 0.8709\n",
      "Epoch 3/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.3684 - acc: 0.8677 - val_loss: 0.2803 - val_acc: 0.9038\n",
      "Epoch 4/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2775 - acc: 0.9063 - val_loss: 0.2234 - val_acc: 0.9266\n",
      "Epoch 5/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2389 - acc: 0.9171 - val_loss: 0.1933 - val_acc: 0.9367\n",
      "Epoch 6/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1966 - acc: 0.9373 - val_loss: 0.1634 - val_acc: 0.9443\n",
      "Epoch 7/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1743 - acc: 0.9475 - val_loss: 0.1536 - val_acc: 0.9468\n",
      "Epoch 8/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1558 - acc: 0.9538 - val_loss: 0.1479 - val_acc: 0.9443\n",
      "Epoch 9/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1470 - acc: 0.9557 - val_loss: 0.1461 - val_acc: 0.9443\n",
      "Epoch 10/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1344 - acc: 0.9595 - val_loss: 0.1335 - val_acc: 0.9494\n",
      "Epoch 11/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1271 - acc: 0.9601 - val_loss: 0.1279 - val_acc: 0.9494\n",
      "Epoch 12/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1172 - acc: 0.9665 - val_loss: 0.1259 - val_acc: 0.9418\n",
      "Epoch 13/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1125 - acc: 0.9690 - val_loss: 0.1245 - val_acc: 0.9620\n",
      "Epoch 14/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1003 - acc: 0.9734 - val_loss: 0.1360 - val_acc: 0.9443\n",
      "Epoch 15/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1027 - acc: 0.9665 - val_loss: 0.1266 - val_acc: 0.9570\n",
      "Epoch 16/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1014 - acc: 0.9722 - val_loss: 0.1157 - val_acc: 0.9544\n",
      "Epoch 17/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0933 - acc: 0.9690 - val_loss: 0.1189 - val_acc: 0.9544\n",
      "Epoch 18/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0890 - acc: 0.9734 - val_loss: 0.1200 - val_acc: 0.9494\n",
      "Epoch 19/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0862 - acc: 0.9772 - val_loss: 0.1194 - val_acc: 0.9595\n",
      "Epoch 20/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0824 - acc: 0.9778 - val_loss: 0.1170 - val_acc: 0.9570\n",
      "Epoch 21/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0820 - acc: 0.9797 - val_loss: 0.1127 - val_acc: 0.9544\n",
      "Epoch 22/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0736 - acc: 0.9797 - val_loss: 0.1161 - val_acc: 0.9494\n",
      "Epoch 23/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0716 - acc: 0.9816 - val_loss: 0.1165 - val_acc: 0.9443\n",
      "Epoch 24/100\n",
      "1580/1580 [==============================] - ETA: 0s - loss: 0.0715 - acc: 0.978 - 0s - loss: 0.0722 - acc: 0.9785 - val_loss: 0.1152 - val_acc: 0.9494\n",
      "Epoch 25/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0597 - acc: 0.9829 - val_loss: 0.1188 - val_acc: 0.9595\n",
      "Epoch 26/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0708 - acc: 0.9797 - val_loss: 0.1180 - val_acc: 0.9646\n",
      "Epoch 27/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0673 - acc: 0.9842 - val_loss: 0.1126 - val_acc: 0.9570\n",
      "Epoch 28/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0606 - acc: 0.9810 - val_loss: 0.1197 - val_acc: 0.9468\n",
      "Epoch 29/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0660 - acc: 0.9797 - val_loss: 0.1217 - val_acc: 0.9570\n",
      "Epoch 30/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0583 - acc: 0.9835 - val_loss: 0.1121 - val_acc: 0.9595\n",
      "Epoch 31/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0585 - acc: 0.9848 - val_loss: 0.1179 - val_acc: 0.9468\n",
      "Epoch 32/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0576 - acc: 0.9842 - val_loss: 0.1238 - val_acc: 0.9595\n",
      "Epoch 33/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0494 - acc: 0.9873 - val_loss: 0.1270 - val_acc: 0.9544\n",
      "Epoch 34/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0550 - acc: 0.9848 - val_loss: 0.1239 - val_acc: 0.9620\n",
      "Epoch 35/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0440 - acc: 0.9886 - val_loss: 0.1158 - val_acc: 0.9570\n",
      "Epoch 36/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0536 - acc: 0.9842 - val_loss: 0.1205 - val_acc: 0.9595\n",
      "Epoch 37/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0496 - acc: 0.9854 - val_loss: 0.1298 - val_acc: 0.9519\n",
      "Epoch 38/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0446 - acc: 0.9873 - val_loss: 0.1249 - val_acc: 0.9519\n",
      "Epoch 39/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0553 - acc: 0.9816 - val_loss: 0.1281 - val_acc: 0.9620\n",
      "Epoch 40/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0453 - acc: 0.9861 - val_loss: 0.1364 - val_acc: 0.9570\n",
      "Epoch 41/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0517 - acc: 0.9778 - val_loss: 0.1281 - val_acc: 0.9646\n",
      "Epoch 42/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0528 - acc: 0.9829 - val_loss: 0.1327 - val_acc: 0.95190.982\n",
      "Epoch 43/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0475 - acc: 0.9867 - val_loss: 0.1261 - val_acc: 0.9595\n",
      "Epoch 44/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0455 - acc: 0.9880 - val_loss: 0.1317 - val_acc: 0.9595\n",
      "Epoch 45/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0501 - acc: 0.9880 - val_loss: 0.1282 - val_acc: 0.9646\n",
      "Epoch 46/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0502 - acc: 0.9842 - val_loss: 0.1488 - val_acc: 0.9570\n",
      "Epoch 47/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0407 - acc: 0.9867 - val_loss: 0.1310 - val_acc: 0.9595\n",
      "Epoch 48/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0380 - acc: 0.9867 - val_loss: 0.1440 - val_acc: 0.9544\n",
      "Epoch 49/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0335 - acc: 0.9905 - val_loss: 0.1179 - val_acc: 0.9722\n",
      "Epoch 50/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0313 - acc: 0.9918 - val_loss: 0.1140 - val_acc: 0.9646\n",
      "Epoch 51/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0274 - acc: 0.9924 - val_loss: 0.1400 - val_acc: 0.9595\n",
      "Epoch 52/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0406 - acc: 0.9873 - val_loss: 0.1270 - val_acc: 0.9671\n",
      "Epoch 53/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0382 - acc: 0.9899 - val_loss: 0.1306 - val_acc: 0.9620\n",
      "Epoch 54/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0328 - acc: 0.9918 - val_loss: 0.1280 - val_acc: 0.9646\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0330 - acc: 0.9918 - val_loss: 0.1266 - val_acc: 0.9696\n",
      "Epoch 56/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0326 - acc: 0.9892 - val_loss: 0.1274 - val_acc: 0.9671\n",
      "Epoch 57/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0315 - acc: 0.9918 - val_loss: 0.1363 - val_acc: 0.9671\n",
      "Epoch 58/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0256 - acc: 0.9930 - val_loss: 0.1393 - val_acc: 0.9646\n",
      "Epoch 59/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0363 - acc: 0.9899 - val_loss: 0.1366 - val_acc: 0.9646\n",
      "Epoch 60/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0228 - acc: 0.9937 - val_loss: 0.1503 - val_acc: 0.9519\n",
      "Epoch 61/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0293 - acc: 0.9924 - val_loss: 0.1491 - val_acc: 0.9570\n",
      "Epoch 62/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0285 - acc: 0.9930 - val_loss: 0.1552 - val_acc: 0.9570\n",
      "Epoch 63/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0251 - acc: 0.9905 - val_loss: 0.1481 - val_acc: 0.9620\n",
      "Epoch 64/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0208 - acc: 0.9937 - val_loss: 0.1523 - val_acc: 0.9595\n",
      "Epoch 65/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0338 - acc: 0.9924 - val_loss: 0.1482 - val_acc: 0.9620\n",
      "Epoch 66/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0219 - acc: 0.9930 - val_loss: 0.1621 - val_acc: 0.9595\n",
      "Epoch 67/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0264 - acc: 0.9918 - val_loss: 0.1642 - val_acc: 0.9468\n",
      "Epoch 68/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0228 - acc: 0.9937 - val_loss: 0.1789 - val_acc: 0.9544\n",
      "Epoch 69/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0224 - acc: 0.9937 - val_loss: 0.1660 - val_acc: 0.9570\n",
      "Epoch 70/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0187 - acc: 0.9962 - val_loss: 0.1725 - val_acc: 0.9468\n",
      "Epoch 71/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0189 - acc: 0.9949 - val_loss: 0.1742 - val_acc: 0.9519\n",
      "Epoch 72/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0233 - acc: 0.9937 - val_loss: 0.1883 - val_acc: 0.9418\n",
      "Epoch 73/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0241 - acc: 0.9892 - val_loss: 0.1814 - val_acc: 0.9519\n",
      "Epoch 74/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0314 - acc: 0.9892 - val_loss: 0.1702 - val_acc: 0.9570\n",
      "Epoch 75/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0318 - acc: 0.9899 - val_loss: 0.1762 - val_acc: 0.9570\n",
      "Epoch 76/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0172 - acc: 0.9924 - val_loss: 0.1842 - val_acc: 0.9494\n",
      "Epoch 77/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0173 - acc: 0.9943 - val_loss: 0.2043 - val_acc: 0.9468\n",
      "Epoch 78/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0176 - acc: 0.9930 - val_loss: 0.1698 - val_acc: 0.9519\n",
      "Epoch 79/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0234 - acc: 0.9911 - val_loss: 0.1721 - val_acc: 0.9620\n",
      "Epoch 80/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0161 - acc: 0.9943 - val_loss: 0.1629 - val_acc: 0.9595\n",
      "Epoch 81/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0171 - acc: 0.9949 - val_loss: 0.1784 - val_acc: 0.9519\n",
      "Epoch 82/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0191 - acc: 0.9924 - val_loss: 0.1835 - val_acc: 0.9468\n",
      "Epoch 83/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0253 - acc: 0.9949 - val_loss: 0.1823 - val_acc: 0.9494\n",
      "Epoch 84/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0194 - acc: 0.9937 - val_loss: 0.1926 - val_acc: 0.9443\n",
      "Epoch 85/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0149 - acc: 0.9962 - val_loss: 0.2058 - val_acc: 0.9468\n",
      "Epoch 86/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0220 - acc: 0.9924 - val_loss: 0.1972 - val_acc: 0.9494\n",
      "Epoch 87/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0193 - acc: 0.9937 - val_loss: 0.2098 - val_acc: 0.9443\n",
      "Epoch 88/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0224 - acc: 0.9949 - val_loss: 0.2091 - val_acc: 0.9494\n",
      "Epoch 89/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0187 - acc: 0.9924 - val_loss: 0.2016 - val_acc: 0.9570\n",
      "Epoch 90/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0177 - acc: 0.9949 - val_loss: 0.1958 - val_acc: 0.9519\n",
      "Epoch 91/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0237 - acc: 0.9937 - val_loss: 0.2022 - val_acc: 0.9392\n",
      "Epoch 92/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0115 - acc: 0.9968 - val_loss: 0.2099 - val_acc: 0.9494\n",
      "Epoch 93/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0129 - acc: 0.9962 - val_loss: 0.1986 - val_acc: 0.9519\n",
      "Epoch 94/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0143 - acc: 0.9975 - val_loss: 0.2197 - val_acc: 0.9494\n",
      "Epoch 95/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0106 - acc: 0.9962 - val_loss: 0.2237 - val_acc: 0.9418\n",
      "Epoch 96/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0133 - acc: 0.9975 - val_loss: 0.2221 - val_acc: 0.9468\n",
      "Epoch 97/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0169 - acc: 0.9968 - val_loss: 0.2075 - val_acc: 0.9544\n",
      "Epoch 98/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0098 - acc: 0.9987 - val_loss: 0.2086 - val_acc: 0.9468\n",
      "Epoch 99/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0104 - acc: 0.9968 - val_loss: 0.2182 - val_acc: 0.9468\n",
      "Epoch 100/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.2131 - val_acc: 0.9418\n",
      " 32/696 [>.............................] - ETA: 6sfor subsample 2, its accuarcy is 0.8491\n",
      "Train on 1580 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1580/1580 [==============================] - 0s - loss: 1.0739 - acc: 0.6013 - val_loss: 0.6573 - val_acc: 0.7696\n",
      "Epoch 2/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.5633 - acc: 0.7880 - val_loss: 0.4328 - val_acc: 0.8253\n",
      "Epoch 3/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.4017 - acc: 0.8506 - val_loss: 0.3411 - val_acc: 0.8684\n",
      "Epoch 4/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.3253 - acc: 0.8867 - val_loss: 0.3035 - val_acc: 0.8633\n",
      "Epoch 5/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2776 - acc: 0.9051 - val_loss: 0.2810 - val_acc: 0.8835\n",
      "Epoch 6/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2343 - acc: 0.9234 - val_loss: 0.2694 - val_acc: 0.8861\n",
      "Epoch 7/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2173 - acc: 0.9342 - val_loss: 0.2508 - val_acc: 0.9038\n",
      "Epoch 8/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2027 - acc: 0.9354 - val_loss: 0.2527 - val_acc: 0.9038\n",
      "Epoch 9/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1915 - acc: 0.9386 - val_loss: 0.2403 - val_acc: 0.9114\n",
      "Epoch 10/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1810 - acc: 0.9418 - val_loss: 0.2417 - val_acc: 0.9165\n",
      "Epoch 11/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1635 - acc: 0.9494 - val_loss: 0.2417 - val_acc: 0.9013\n",
      "Epoch 12/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1489 - acc: 0.9538 - val_loss: 0.2529 - val_acc: 0.9190\n",
      "Epoch 13/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1548 - acc: 0.9519 - val_loss: 0.2504 - val_acc: 0.9139\n",
      "Epoch 14/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1467 - acc: 0.9589 - val_loss: 0.2557 - val_acc: 0.9165\n",
      "Epoch 15/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1399 - acc: 0.9576 - val_loss: 0.2569 - val_acc: 0.9139\n",
      "Epoch 16/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1275 - acc: 0.9627 - val_loss: 0.2647 - val_acc: 0.9089\n",
      "Epoch 17/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1229 - acc: 0.9614 - val_loss: 0.2647 - val_acc: 0.9114\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.1226 - acc: 0.9633 - val_loss: 0.2887 - val_acc: 0.9114\n",
      "Epoch 19/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1106 - acc: 0.9652 - val_loss: 0.2795 - val_acc: 0.9114\n",
      "Epoch 20/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1058 - acc: 0.9715 - val_loss: 0.2955 - val_acc: 0.9089\n",
      "Epoch 21/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1038 - acc: 0.9741 - val_loss: 0.2957 - val_acc: 0.9165\n",
      "Epoch 22/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0959 - acc: 0.9703 - val_loss: 0.3056 - val_acc: 0.9038\n",
      "Epoch 23/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0983 - acc: 0.9728 - val_loss: 0.3202 - val_acc: 0.8962\n",
      "Epoch 24/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0851 - acc: 0.9741 - val_loss: 0.3279 - val_acc: 0.9089\n",
      "Epoch 25/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0800 - acc: 0.9804 - val_loss: 0.3290 - val_acc: 0.9139\n",
      "Epoch 26/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0832 - acc: 0.9766 - val_loss: 0.3402 - val_acc: 0.9063\n",
      "Epoch 27/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0801 - acc: 0.9791 - val_loss: 0.3437 - val_acc: 0.9114\n",
      "Epoch 28/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0762 - acc: 0.9778 - val_loss: 0.3583 - val_acc: 0.9038\n",
      "Epoch 29/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0752 - acc: 0.9791 - val_loss: 0.3562 - val_acc: 0.9038\n",
      "Epoch 30/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0704 - acc: 0.9778 - val_loss: 0.3563 - val_acc: 0.9038\n",
      "Epoch 31/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0722 - acc: 0.9759 - val_loss: 0.3657 - val_acc: 0.9063\n",
      "Epoch 32/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0717 - acc: 0.9759 - val_loss: 0.3824 - val_acc: 0.9114\n",
      "Epoch 33/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0610 - acc: 0.9854 - val_loss: 0.3826 - val_acc: 0.9038\n",
      "Epoch 34/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0752 - acc: 0.9785 - val_loss: 0.3761 - val_acc: 0.9063\n",
      "Epoch 35/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0574 - acc: 0.9842 - val_loss: 0.3837 - val_acc: 0.9063\n",
      "Epoch 36/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0623 - acc: 0.9848 - val_loss: 0.3860 - val_acc: 0.9165\n",
      "Epoch 37/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0578 - acc: 0.9823 - val_loss: 0.4042 - val_acc: 0.9089\n",
      "Epoch 38/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0569 - acc: 0.9854 - val_loss: 0.3997 - val_acc: 0.9089\n",
      "Epoch 39/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0516 - acc: 0.9867 - val_loss: 0.4132 - val_acc: 0.9038\n",
      "Epoch 40/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0543 - acc: 0.9816 - val_loss: 0.4233 - val_acc: 0.9038\n",
      "Epoch 41/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0500 - acc: 0.9861 - val_loss: 0.4266 - val_acc: 0.9038\n",
      "Epoch 42/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0555 - acc: 0.9823 - val_loss: 0.4356 - val_acc: 0.9063\n",
      "Epoch 43/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0524 - acc: 0.9842 - val_loss: 0.4441 - val_acc: 0.9063\n",
      "Epoch 44/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0602 - acc: 0.9778 - val_loss: 0.4481 - val_acc: 0.9139\n",
      "Epoch 45/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0493 - acc: 0.9835 - val_loss: 0.4713 - val_acc: 0.9013\n",
      "Epoch 46/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0493 - acc: 0.9861 - val_loss: 0.4703 - val_acc: 0.9089\n",
      "Epoch 47/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0503 - acc: 0.9848 - val_loss: 0.4715 - val_acc: 0.9063\n",
      "Epoch 48/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0518 - acc: 0.9848 - val_loss: 0.4736 - val_acc: 0.9063\n",
      "Epoch 49/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0409 - acc: 0.9918 - val_loss: 0.4794 - val_acc: 0.9089\n",
      "Epoch 50/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0389 - acc: 0.9892 - val_loss: 0.4762 - val_acc: 0.9089\n",
      "Epoch 51/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0491 - acc: 0.9861 - val_loss: 0.4920 - val_acc: 0.9089\n",
      "Epoch 52/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0480 - acc: 0.9848 - val_loss: 0.4905 - val_acc: 0.9063\n",
      "Epoch 53/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0463 - acc: 0.9854 - val_loss: 0.4891 - val_acc: 0.9139\n",
      "Epoch 54/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0405 - acc: 0.9886 - val_loss: 0.5314 - val_acc: 0.9013\n",
      "Epoch 55/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0403 - acc: 0.9861 - val_loss: 0.5270 - val_acc: 0.9114\n",
      "Epoch 56/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0385 - acc: 0.9905 - val_loss: 0.5229 - val_acc: 0.9063\n",
      "Epoch 57/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0405 - acc: 0.9899 - val_loss: 0.5111 - val_acc: 0.9114\n",
      "Epoch 58/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0327 - acc: 0.9899 - val_loss: 0.5103 - val_acc: 0.9013\n",
      "Epoch 59/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0335 - acc: 0.9892 - val_loss: 0.5301 - val_acc: 0.9063\n",
      "Epoch 60/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0404 - acc: 0.9886 - val_loss: 0.5538 - val_acc: 0.9089\n",
      "Epoch 61/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0411 - acc: 0.9886 - val_loss: 0.5488 - val_acc: 0.9089\n",
      "Epoch 62/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0325 - acc: 0.9918 - val_loss: 0.5493 - val_acc: 0.9139\n",
      "Epoch 63/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0332 - acc: 0.9886 - val_loss: 0.5608 - val_acc: 0.9165\n",
      "Epoch 64/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0386 - acc: 0.9867 - val_loss: 0.5491 - val_acc: 0.9114\n",
      "Epoch 65/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0360 - acc: 0.9918 - val_loss: 0.5673 - val_acc: 0.9038\n",
      "Epoch 66/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0383 - acc: 0.9854 - val_loss: 0.5748 - val_acc: 0.9089\n",
      "Epoch 67/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0323 - acc: 0.9905 - val_loss: 0.5917 - val_acc: 0.9013\n",
      "Epoch 68/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0347 - acc: 0.9918 - val_loss: 0.5810 - val_acc: 0.9089\n",
      "Epoch 69/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0423 - acc: 0.9880 - val_loss: 0.5879 - val_acc: 0.9063\n",
      "Epoch 70/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0377 - acc: 0.9905 - val_loss: 0.6040 - val_acc: 0.9063\n",
      "Epoch 71/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0365 - acc: 0.9880 - val_loss: 0.6105 - val_acc: 0.9114\n",
      "Epoch 72/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0437 - acc: 0.9835 - val_loss: 0.6250 - val_acc: 0.9038\n",
      "Epoch 73/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0348 - acc: 0.9911 - val_loss: 0.6196 - val_acc: 0.9089\n",
      "Epoch 74/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0447 - acc: 0.9867 - val_loss: 0.6341 - val_acc: 0.9038\n",
      "Epoch 75/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0339 - acc: 0.9867 - val_loss: 0.6112 - val_acc: 0.9063\n",
      "Epoch 76/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0230 - acc: 0.9937 - val_loss: 0.6143 - val_acc: 0.9089\n",
      "Epoch 77/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0311 - acc: 0.9924 - val_loss: 0.6241 - val_acc: 0.9114\n",
      "Epoch 78/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0309 - acc: 0.9892 - val_loss: 0.5982 - val_acc: 0.9165\n",
      "Epoch 79/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0277 - acc: 0.9956 - val_loss: 0.6238 - val_acc: 0.9038\n",
      "Epoch 80/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0210 - acc: 0.9956 - val_loss: 0.6248 - val_acc: 0.9114\n",
      "Epoch 81/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0222 - acc: 0.9918 - val_loss: 0.6327 - val_acc: 0.9089\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0247 - acc: 0.9962 - val_loss: 0.6573 - val_acc: 0.9038\n",
      "Epoch 83/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0280 - acc: 0.9918 - val_loss: 0.6408 - val_acc: 0.9063\n",
      "Epoch 84/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0246 - acc: 0.9924 - val_loss: 0.6361 - val_acc: 0.9114\n",
      "Epoch 85/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0169 - acc: 0.9943 - val_loss: 0.6183 - val_acc: 0.9063\n",
      "Epoch 86/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0276 - acc: 0.9930 - val_loss: 0.6500 - val_acc: 0.9089\n",
      "Epoch 87/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0238 - acc: 0.9924 - val_loss: 0.6580 - val_acc: 0.9165\n",
      "Epoch 88/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0247 - acc: 0.9918 - val_loss: 0.6479 - val_acc: 0.9089\n",
      "Epoch 89/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0185 - acc: 0.9949 - val_loss: 0.6415 - val_acc: 0.9038\n",
      "Epoch 90/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0279 - acc: 0.9937 - val_loss: 0.6632 - val_acc: 0.9139\n",
      "Epoch 91/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0218 - acc: 0.9962 - val_loss: 0.6597 - val_acc: 0.9114\n",
      "Epoch 92/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0246 - acc: 0.9949 - val_loss: 0.6720 - val_acc: 0.9089\n",
      "Epoch 93/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0239 - acc: 0.9943 - val_loss: 0.6722 - val_acc: 0.9139\n",
      "Epoch 94/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0212 - acc: 0.9949 - val_loss: 0.6862 - val_acc: 0.9089\n",
      "Epoch 95/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0190 - acc: 0.9943 - val_loss: 0.6666 - val_acc: 0.9139\n",
      "Epoch 96/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0241 - acc: 0.9924 - val_loss: 0.6854 - val_acc: 0.9114\n",
      "Epoch 97/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0142 - acc: 0.9962 - val_loss: 0.7074 - val_acc: 0.9089\n",
      "Epoch 98/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0237 - acc: 0.9937 - val_loss: 0.6874 - val_acc: 0.9089\n",
      "Epoch 99/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0221 - acc: 0.9911 - val_loss: 0.7212 - val_acc: 0.9063\n",
      "Epoch 100/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0114 - acc: 0.9968 - val_loss: 0.7085 - val_acc: 0.9089\n",
      " 32/696 [>.............................] - ETA: 6sfor subsample 3, its accuarcy is 0.8764\n",
      "Train on 1580 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1580/1580 [==============================] - 0s - loss: 1.0898 - acc: 0.6190 - val_loss: 0.6595 - val_acc: 0.8101\n",
      "Epoch 2/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.5938 - acc: 0.7810 - val_loss: 0.4157 - val_acc: 0.8861\n",
      "Epoch 3/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.4033 - acc: 0.8627 - val_loss: 0.3080 - val_acc: 0.8987\n",
      "Epoch 4/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2934 - acc: 0.9025 - val_loss: 0.2603 - val_acc: 0.9165\n",
      "Epoch 5/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2525 - acc: 0.9215 - val_loss: 0.2382 - val_acc: 0.9316\n",
      "Epoch 6/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.2232 - acc: 0.9304 - val_loss: 0.2315 - val_acc: 0.9241\n",
      "Epoch 7/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1925 - acc: 0.9405 - val_loss: 0.2231 - val_acc: 0.9190\n",
      "Epoch 8/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1721 - acc: 0.9424 - val_loss: 0.2138 - val_acc: 0.9215\n",
      "Epoch 9/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1531 - acc: 0.9449 - val_loss: 0.2255 - val_acc: 0.8987\n",
      "Epoch 10/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1457 - acc: 0.9500 - val_loss: 0.2019 - val_acc: 0.9215\n",
      "Epoch 11/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1352 - acc: 0.9589 - val_loss: 0.2003 - val_acc: 0.9215\n",
      "Epoch 12/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1229 - acc: 0.9639 - val_loss: 0.2019 - val_acc: 0.9241\n",
      "Epoch 13/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1149 - acc: 0.9620 - val_loss: 0.2003 - val_acc: 0.9241\n",
      "Epoch 14/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1134 - acc: 0.9665 - val_loss: 0.2072 - val_acc: 0.9190\n",
      "Epoch 15/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1063 - acc: 0.9677 - val_loss: 0.2234 - val_acc: 0.9291\n",
      "Epoch 16/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1127 - acc: 0.9658 - val_loss: 0.1989 - val_acc: 0.9367\n",
      "Epoch 17/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0854 - acc: 0.9728 - val_loss: 0.2152 - val_acc: 0.9342\n",
      "Epoch 18/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.1009 - acc: 0.9658 - val_loss: 0.2130 - val_acc: 0.9215\n",
      "Epoch 19/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0869 - acc: 0.9766 - val_loss: 0.2095 - val_acc: 0.9266\n",
      "Epoch 20/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0773 - acc: 0.9759 - val_loss: 0.2018 - val_acc: 0.9367\n",
      "Epoch 21/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0831 - acc: 0.9753 - val_loss: 0.2083 - val_acc: 0.9241\n",
      "Epoch 22/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0776 - acc: 0.9772 - val_loss: 0.2033 - val_acc: 0.9342\n",
      "Epoch 23/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0708 - acc: 0.9785 - val_loss: 0.2140 - val_acc: 0.9266\n",
      "Epoch 24/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0822 - acc: 0.9772 - val_loss: 0.2202 - val_acc: 0.9342\n",
      "Epoch 25/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0707 - acc: 0.9772 - val_loss: 0.2220 - val_acc: 0.9241\n",
      "Epoch 26/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0603 - acc: 0.9835 - val_loss: 0.2164 - val_acc: 0.9392\n",
      "Epoch 27/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0721 - acc: 0.9816 - val_loss: 0.2205 - val_acc: 0.9367\n",
      "Epoch 28/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0669 - acc: 0.9785 - val_loss: 0.2075 - val_acc: 0.9367\n",
      "Epoch 29/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0545 - acc: 0.9835 - val_loss: 0.2230 - val_acc: 0.9367\n",
      "Epoch 30/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0550 - acc: 0.9829 - val_loss: 0.2349 - val_acc: 0.9418\n",
      "Epoch 31/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0576 - acc: 0.9816 - val_loss: 0.2356 - val_acc: 0.9468\n",
      "Epoch 32/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0570 - acc: 0.9835 - val_loss: 0.2381 - val_acc: 0.9418\n",
      "Epoch 33/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0457 - acc: 0.9848 - val_loss: 0.2603 - val_acc: 0.9367\n",
      "Epoch 34/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0469 - acc: 0.9842 - val_loss: 0.2439 - val_acc: 0.9418\n",
      "Epoch 35/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0505 - acc: 0.9823 - val_loss: 0.2359 - val_acc: 0.9418\n",
      "Epoch 36/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0572 - acc: 0.9797 - val_loss: 0.2583 - val_acc: 0.9367\n",
      "Epoch 37/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0470 - acc: 0.9842 - val_loss: 0.2571 - val_acc: 0.9443\n",
      "Epoch 38/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0484 - acc: 0.9842 - val_loss: 0.2714 - val_acc: 0.9468\n",
      "Epoch 39/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0517 - acc: 0.9861 - val_loss: 0.2738 - val_acc: 0.9418\n",
      "Epoch 40/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0389 - acc: 0.9867 - val_loss: 0.2804 - val_acc: 0.9367\n",
      "Epoch 41/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0442 - acc: 0.9886 - val_loss: 0.2963 - val_acc: 0.9392\n",
      "Epoch 42/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0404 - acc: 0.9848 - val_loss: 0.2902 - val_acc: 0.9392\n",
      "Epoch 43/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0457 - acc: 0.9873 - val_loss: 0.2952 - val_acc: 0.9418\n",
      "Epoch 44/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0407 - acc: 0.9867 - val_loss: 0.2995 - val_acc: 0.9367\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 0s - loss: 0.0357 - acc: 0.9880 - val_loss: 0.2897 - val_acc: 0.9494\n",
      "Epoch 46/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0329 - acc: 0.9886 - val_loss: 0.3181 - val_acc: 0.9468\n",
      "Epoch 47/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0390 - acc: 0.9861 - val_loss: 0.2942 - val_acc: 0.9392\n",
      "Epoch 48/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0467 - acc: 0.9861 - val_loss: 0.3174 - val_acc: 0.9392\n",
      "Epoch 49/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0431 - acc: 0.9842 - val_loss: 0.3120 - val_acc: 0.9392\n",
      "Epoch 50/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0350 - acc: 0.9892 - val_loss: 0.3096 - val_acc: 0.9392\n",
      "Epoch 51/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0341 - acc: 0.9880 - val_loss: 0.3205 - val_acc: 0.9519\n",
      "Epoch 52/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0338 - acc: 0.9905 - val_loss: 0.3196 - val_acc: 0.9367\n",
      "Epoch 53/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0343 - acc: 0.9873 - val_loss: 0.3388 - val_acc: 0.9418\n",
      "Epoch 54/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0227 - acc: 0.9943 - val_loss: 0.3346 - val_acc: 0.9468\n",
      "Epoch 55/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0310 - acc: 0.9892 - val_loss: 0.3344 - val_acc: 0.9418\n",
      "Epoch 56/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0299 - acc: 0.9918 - val_loss: 0.3471 - val_acc: 0.9367\n",
      "Epoch 57/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0319 - acc: 0.9899 - val_loss: 0.3469 - val_acc: 0.9418\n",
      "Epoch 58/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0488 - acc: 0.9816 - val_loss: 0.3569 - val_acc: 0.9418\n",
      "Epoch 59/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0336 - acc: 0.9892 - val_loss: 0.3657 - val_acc: 0.9342\n",
      "Epoch 60/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0377 - acc: 0.9873 - val_loss: 0.3536 - val_acc: 0.9418\n",
      "Epoch 61/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0378 - acc: 0.9867 - val_loss: 0.3517 - val_acc: 0.9418\n",
      "Epoch 62/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0254 - acc: 0.9911 - val_loss: 0.3628 - val_acc: 0.9392\n",
      "Epoch 63/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0268 - acc: 0.9930 - val_loss: 0.3743 - val_acc: 0.9418\n",
      "Epoch 64/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0280 - acc: 0.9886 - val_loss: 0.3747 - val_acc: 0.9367\n",
      "Epoch 65/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0206 - acc: 0.9943 - val_loss: 0.3818 - val_acc: 0.9468\n",
      "Epoch 66/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0242 - acc: 0.9937 - val_loss: 0.3785 - val_acc: 0.9418\n",
      "Epoch 67/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0255 - acc: 0.9924 - val_loss: 0.3974 - val_acc: 0.9392\n",
      "Epoch 68/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0316 - acc: 0.9886 - val_loss: 0.3971 - val_acc: 0.9418\n",
      "Epoch 69/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0230 - acc: 0.9924 - val_loss: 0.4071 - val_acc: 0.9392\n",
      "Epoch 70/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0197 - acc: 0.9943 - val_loss: 0.4047 - val_acc: 0.9392\n",
      "Epoch 71/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0284 - acc: 0.9886 - val_loss: 0.4025 - val_acc: 0.9443\n",
      "Epoch 72/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0245 - acc: 0.9911 - val_loss: 0.4029 - val_acc: 0.9418\n",
      "Epoch 73/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0241 - acc: 0.9930 - val_loss: 0.4368 - val_acc: 0.9367\n",
      "Epoch 74/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0274 - acc: 0.9924 - val_loss: 0.4100 - val_acc: 0.9367\n",
      "Epoch 75/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.4123 - val_acc: 0.9342\n",
      "Epoch 76/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0205 - acc: 0.9930 - val_loss: 0.4084 - val_acc: 0.9392\n",
      "Epoch 77/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0147 - acc: 0.9962 - val_loss: 0.4058 - val_acc: 0.9443\n",
      "Epoch 78/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0173 - acc: 0.9962 - val_loss: 0.4045 - val_acc: 0.9418\n",
      "Epoch 79/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0204 - acc: 0.9937 - val_loss: 0.4219 - val_acc: 0.9367\n",
      "Epoch 80/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0208 - acc: 0.9899 - val_loss: 0.4371 - val_acc: 0.9342\n",
      "Epoch 81/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0180 - acc: 0.9937 - val_loss: 0.4307 - val_acc: 0.9392\n",
      "Epoch 82/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0332 - acc: 0.9899 - val_loss: 0.4309 - val_acc: 0.9367\n",
      "Epoch 83/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0210 - acc: 0.9918 - val_loss: 0.4457 - val_acc: 0.9367\n",
      "Epoch 84/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0177 - acc: 0.9943 - val_loss: 0.4363 - val_acc: 0.9443\n",
      "Epoch 85/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0193 - acc: 0.9937 - val_loss: 0.4490 - val_acc: 0.9418\n",
      "Epoch 86/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0233 - acc: 0.9911 - val_loss: 0.4604 - val_acc: 0.9418\n",
      "Epoch 87/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0211 - acc: 0.9911 - val_loss: 0.4676 - val_acc: 0.9392\n",
      "Epoch 88/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0273 - acc: 0.9899 - val_loss: 0.4621 - val_acc: 0.9418\n",
      "Epoch 89/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0300 - acc: 0.9873 - val_loss: 0.4508 - val_acc: 0.9392\n",
      "Epoch 90/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0216 - acc: 0.9905 - val_loss: 0.4552 - val_acc: 0.9443\n",
      "Epoch 91/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0262 - acc: 0.9918 - val_loss: 0.4463 - val_acc: 0.9418\n",
      "Epoch 92/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0204 - acc: 0.9937 - val_loss: 0.4598 - val_acc: 0.9443\n",
      "Epoch 93/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0169 - acc: 0.9943 - val_loss: 0.4705 - val_acc: 0.9443\n",
      "Epoch 94/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0184 - acc: 0.9943 - val_loss: 0.4729 - val_acc: 0.9418\n",
      "Epoch 95/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0202 - acc: 0.9930 - val_loss: 0.4749 - val_acc: 0.9443\n",
      "Epoch 96/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0156 - acc: 0.9975 - val_loss: 0.4803 - val_acc: 0.9367\n",
      "Epoch 97/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0132 - acc: 0.9956 - val_loss: 0.4774 - val_acc: 0.9367\n",
      "Epoch 98/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0174 - acc: 0.9937 - val_loss: 0.4933 - val_acc: 0.9367\n",
      "Epoch 99/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0161 - acc: 0.9924 - val_loss: 0.5001 - val_acc: 0.9392\n",
      "Epoch 100/100\n",
      "1580/1580 [==============================] - 0s - loss: 0.0357 - acc: 0.9905 - val_loss: 0.4767 - val_acc: 0.9418\n",
      " 32/696 [>.............................] - ETA: 6sfor subsample 4, its accuarcy is 0.8707\n"
     ]
    }
   ],
   "source": [
    "# print accuarcy of every subsample and get's its prediction\n",
    "l1 = list()\n",
    "for i in range(5):\n",
    "    train_x, train_y = subsample(train_r_features, train_labels)\n",
    "    train_x2, val_x2, train_y2, val_y2 = train_val(train_x, train_y)\n",
    "    model = classifier()\n",
    "    model.fit(train_x2, train_y2, validation_data=(val_x2, val_y2), nb_epoch=nb_epochs, batch_size=batch_size)\n",
    "    loss, acc = model.evaluate(test_r_features, test_labels)\n",
    "    l1.append(model.predict_classes(test_r_features))\n",
    "    print(\"for subsample %d, its accuarcy is %.4f\" % (i,acc)) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 4, 0, 4, 3, 0, 4, 3, 3, 3, 0, 1, 0, 4, 0, 4, 2, 1, 1, 0,\n",
       "       0, 4, 0, 0, 4, 0, 3, 0, 0, 1, 4, 0, 4, 1, 4, 4, 3, 3, 1, 0, 1, 3, 1,\n",
       "       0, 0, 4, 4, 3, 0, 0, 0, 4, 3, 3, 4, 2, 3, 3, 0, 0, 0, 1, 3, 3, 1, 4,\n",
       "       3, 0, 4, 4, 4, 0, 3, 3, 0, 1, 3, 3, 0, 4, 0, 1, 0, 0, 3, 0, 4, 3, 3,\n",
       "       0, 4, 4, 0, 0, 3, 3, 4, 0, 3, 4, 4, 3, 3, 2, 0, 3, 1, 1, 4, 3, 1, 4,\n",
       "       0, 0, 3, 3, 3, 4, 0, 1, 3, 0, 0, 3, 3, 0, 3, 0, 4, 4, 3, 0, 0, 0, 4,\n",
       "       0, 0, 0, 4, 0, 0, 1, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 0, 4, 0,\n",
       "       0, 0, 0, 1, 4, 1, 0, 1, 3, 3, 0, 0, 4, 4, 0, 4, 3, 0, 3, 0, 3, 4, 4,\n",
       "       1, 3, 4, 0, 1, 0, 4, 3, 0, 4, 3, 4, 2, 4, 3, 4, 4, 1, 0, 3, 4, 4, 2,\n",
       "       0, 4, 1, 3, 2, 0, 0, 3, 0, 1, 4, 0, 1, 0, 1, 0, 1, 1, 4, 0, 0, 1, 3,\n",
       "       3, 3, 1, 0, 0, 0, 0, 3, 1, 0, 1, 1, 2, 4, 4, 3, 0, 2, 0, 0, 3, 3, 0,\n",
       "       1, 3, 3, 4, 1, 3, 0, 4, 0, 3, 4, 0, 4, 3, 4, 3, 0, 0, 0, 4, 1, 0, 3,\n",
       "       3, 1, 4, 4, 3, 0, 1, 3, 0, 0, 0, 1, 3, 1, 0, 4, 4, 3, 0, 4, 3, 3, 0,\n",
       "       0, 1, 4, 3, 3, 3, 1, 3, 0, 1, 0, 1, 3, 1, 3, 3, 0, 1, 0, 3, 3, 4, 3,\n",
       "       1, 0, 3, 3, 0, 1, 1, 4, 3, 3, 4, 4, 1, 0, 0, 1, 3, 3, 1, 3, 4, 4, 1,\n",
       "       1, 4, 3, 3, 3, 4, 0, 0, 0, 4, 0, 4, 4, 4, 1, 3, 3, 1, 0, 1, 0, 3, 3,\n",
       "       4, 3, 0, 0, 0, 1, 3, 0, 1, 4, 4, 1, 3, 3, 0, 3, 0, 1, 3, 3, 4, 4, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 3, 3, 3, 1, 3, 0, 3, 4, 1, 1, 3, 1, 3,\n",
       "       1, 0, 0, 4, 0, 0, 1, 0, 3, 1, 4, 0, 3, 4, 3, 0, 3, 3, 4, 0, 4, 0, 1,\n",
       "       0, 0, 1, 4, 0, 1, 3, 3, 0, 3, 2, 0, 3, 0, 3, 2, 0, 0, 3, 4, 0, 4, 1,\n",
       "       3, 4, 1, 0, 0, 3, 0, 4, 0, 0, 3, 0, 3, 0, 4, 1, 3, 4, 0, 1, 0, 3, 0,\n",
       "       4, 0, 3, 3, 4, 0, 1, 0, 3, 2, 3, 0, 4, 0, 1, 0, 1, 3, 3, 1, 3, 1, 4,\n",
       "       3, 3, 4, 4, 0, 4, 4, 3, 1, 3, 1, 3, 3, 1, 3, 3, 3, 0, 3, 1, 0, 1, 0,\n",
       "       1, 1, 3, 1, 0, 0, 0, 1, 4, 1, 3, 0, 0, 3, 1, 3, 4, 0, 0, 1, 0, 1, 3,\n",
       "       0, 4, 0, 3, 1, 3, 4, 0, 4, 0, 4, 1, 3, 4, 1, 4, 1, 0, 1, 0, 4, 3, 3,\n",
       "       3, 3, 0, 1, 1, 0, 4, 0, 0, 3, 1, 3, 0, 3, 4, 0, 1, 0, 3, 4, 1, 4, 3,\n",
       "       0, 4, 3, 0, 3, 0, 1, 1, 3, 0, 3, 3, 0, 4, 0, 0, 0, 4, 4, 4, 0, 0, 4,\n",
       "       1, 4, 3, 4, 3, 3, 4, 4, 3, 0, 0, 4, 0, 3, 1, 4, 1, 0, 1, 0, 0, 3, 3,\n",
       "       0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 3, 3, 3, 4, 1, 0, 1, 1, 3, 3, 3,\n",
       "       4, 4, 0, 0, 0, 3, 3, 3, 1, 1, 0, 3, 1, 4, 3, 0, 4, 3, 3, 3, 0, 4, 0,\n",
       "       1, 3, 1, 1, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 =list(map(list, zip(*l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[1]\n",
    "mode(l2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode, StatisticsError\n",
    "vote = []\n",
    "\n",
    "for i in range(len(l2)):\n",
    "    try:\n",
    "        a = mode(l2[i])\n",
    "        vote.append(a)\n",
    "    except StatisticsError:\n",
    "        vote.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = np.asarray(vote)\n",
    "dummy_vote_label = pd.get_dummies(vote)\n",
    "vote_labels = np.asarray(dummy_vote_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vote_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division \n",
    "a =0\n",
    "\n",
    "for i in range(696):\n",
    "    if np.all(vote_labels[i]) == np.all(test_labels[i]):\n",
    "        a = a + 1\n",
    "\n",
    "print(a)\n",
    "accuarcy = a/696\n",
    "print(accuarcy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = sum(YPred == YTest)/numel(YTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
