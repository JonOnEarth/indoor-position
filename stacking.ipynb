{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers \n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import auto_regression as ar\n",
    "import regular_regression as rr\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "#test\n",
    "#load data\n",
    "path = 'C:/Users/mys12/Desktop/northeastern/summer2018/data_Robust_Fingerprinting-master/DISTRIBUTED_OPENSOURCE/FINGERPRINTING_DB'\n",
    "\n",
    "test_rss = pd.read_csv(path + '/Training_rss_21Aug17.csv', header = 0)\n",
    "test_coord = pd.read_csv(path + '/Training_coordinates_21Aug17.csv', header = 0)\n",
    "test_rss = test_rss.replace(100, 0)\n",
    "\n",
    "train_rss = pd.read_csv(path + '/Test_rss_21Aug17.csv', header = 0)\n",
    "train_coord = pd.read_csv(path + '/Test_coordinates_21Aug17.csv', header = 0)\n",
    "train_rss = train_rss.replace(100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train_rss, train_coord], axis=1, ignore_index=True)\n",
    "test = pd.concat([test_rss, test_coord], axis=1, ignore_index=True)\n",
    "train = np.asarray(train)\n",
    "test = np.asarray(test)\n",
    "\n",
    "# first floor\n",
    "train1 = train[train[:,-1]==0.0]\n",
    "normalizer = preprocessing.Normalizer().fit(train1[:,:-3])\n",
    "train1_r=normalizer.transform(train1[:,:-3])\n",
    "train1_c=train1[:,-3:-1]\n",
    "print(train1_r.shape[1])\n",
    "\n",
    "test1 = test[test[:,-1]==0.0]\n",
    "test1_r=normalizer.transform(test1[:,:-3])\n",
    "test1_c=test1[:,-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predata(rss, locations):\n",
    "    # the origin of the room\n",
    "    origin = np.amin(locations,axis=0)\n",
    "    #size of the room\n",
    "    room_size = np.amax(locations, axis=0)-origin\n",
    "    # position respect to origin\n",
    "    train_Yy = locations - origin\n",
    "    train_Xx = np.asarray(rss, dtype=np.float64)\n",
    "    return train_Xx, train_Yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_val(rss, locations):\n",
    "#     train_Xx, train_Yy = predata(rss, locations)\n",
    "#     train_x, val_x, train_y, val_y = train_test_split(train_Xx, train_Yy, test_size=0.2)\n",
    "#     return train_x, val_x, train_y, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    error = np.sqrt(np.sum((predictions - labels)**2, 1))\n",
    "    return error, np.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = predata(train1_r, train1_c)\n",
    "testX, testY = predata(test1_r, test1_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=rr.train_model\n",
    "clf2=ar.regression\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=4)\n",
    "clf3 = neigh.fit\n",
    "\n",
    "dr = DecisionTreeRegressor(max_depth=7)\n",
    "clf4 = dr.fit\n",
    "\n",
    "er = ExtraTreeRegressor(max_depth=7)\n",
    "clf5 = er.fit\n",
    "\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=2018)\n",
    "\n",
    "#               a = np.zeros(shape=(5,4,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaped(predict):\n",
    "    size = predict.shape[0]\n",
    "    j = predict.reshape((2*size, 1))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, X_train, y_train, X_test):\n",
    "#     X_train = reshaped(X_train)\n",
    "#     y_train = reshaped(y_train)\n",
    "#     X_test = reshaped(X_test)\n",
    "\n",
    "    blend_train = np.zeros((y_train.shape[0],2))\n",
    "    blend_test = np.zeros((X_test.shape[0],2))\n",
    "    blend_test_skf = np.zeros((X_test.shape[0],2,5)) \n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(list(kf.split(X_train))):\n",
    "        print(\"Fold\", i)   \n",
    "\n",
    "        kf_X_train = X_train[train_index]\n",
    "        kf_y_train = y_train[train_index]\n",
    "        kf_X_test = X_train[test_index]\n",
    "        kf_y_test = y_train[test_index]\n",
    "        \n",
    "        model = clf(kf_X_train,kf_y_train)\n",
    "        \n",
    "        blend_train[test_index]=model.predict(kf_X_test)  # 992*2\n",
    "        \n",
    "        blend_test_skf[:,:,i] = model.predict(X_test)   # 1*292*2\n",
    "    \n",
    "    blend_test[:,:]=blend_test_skf.mean(axis=2)\n",
    "    return blend_train, blend_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "blend_train3, blend_test3 = get_oof(clf3, trainX, trainY, testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 103.203   ,   37.66458 ],\n",
       "       [  82.40365 ,   27.53373 ],\n",
       "       [ 114.986   ,   37.99638 ],\n",
       "       [ 132.448   ,   28.57548 ],\n",
       "       [  55.4249  ,   15.64583 ],\n",
       "       [  94.796   ,   53.47178 ],\n",
       "       [  43.45965 ,   19.14968 ],\n",
       "       [ 105.108   ,   24.80828 ],\n",
       "       [  53.98    ,   16.07823 ],\n",
       "       [  66.5732  ,   31.89973 ],\n",
       "       [  77.25165 ,   22.00058 ],\n",
       "       [  69.73575 ,   24.38083 ],\n",
       "       [  67.9996  ,   23.37908 ],\n",
       "       [  53.8442  ,   25.46698 ],\n",
       "       [ 132.      ,   38.07608 ],\n",
       "       [ 119.89    ,   69.55053 ],\n",
       "       [ 133.158   ,   46.06573 ],\n",
       "       [  95.0293  ,   35.93773 ],\n",
       "       [ 139.5045  ,   28.26263 ],\n",
       "       [  23.47205 ,   24.09053 ],\n",
       "       [  59.3365  ,   38.46588 ],\n",
       "       [  80.73075 ,   18.97433 ],\n",
       "       [ 107.9495  ,   18.32258 ],\n",
       "       [  93.3715  ,   62.86078 ],\n",
       "       [ 121.742   ,   66.81118 ],\n",
       "       [  50.91115 ,   24.21203 ],\n",
       "       [  53.66365 ,   16.965875],\n",
       "       [  99.4035  ,   37.05533 ],\n",
       "       [  55.6733  ,   15.04993 ],\n",
       "       [  80.44565 ,   35.13448 ],\n",
       "       [ 105.946   ,   30.64963 ],\n",
       "       [  95.5035  ,   56.77608 ],\n",
       "       [ 140.1745  ,   32.65023 ],\n",
       "       [  86.0861  ,   28.47718 ],\n",
       "       [  97.045   ,   25.55613 ],\n",
       "       [  91.31    ,   67.11598 ],\n",
       "       [ 108.192   ,   19.92863 ],\n",
       "       [  59.18855 ,   16.72813 ],\n",
       "       [  93.6258  ,   28.65898 ],\n",
       "       [  87.147   ,   28.23988 ],\n",
       "       [  58.86105 ,   67.00298 ],\n",
       "       [  83.4294  ,   24.40193 ],\n",
       "       [ 119.0515  ,   15.85505 ],\n",
       "       [ 120.592   ,   70.11523 ],\n",
       "       [  75.74265 ,   24.92688 ],\n",
       "       [ 120.339   ,   67.93643 ],\n",
       "       [  46.0224  ,   29.83498 ],\n",
       "       [  23.98045 ,   21.73963 ],\n",
       "       [ 107.3665  ,   19.71243 ],\n",
       "       [  83.81935 ,   16.94948 ],\n",
       "       [ 167.0805  ,   53.69358 ],\n",
       "       [  66.8767  ,   29.01123 ],\n",
       "       [  61.42175 ,   61.13543 ],\n",
       "       [  61.66475 ,   60.82213 ],\n",
       "       [  65.4572  ,   52.66523 ],\n",
       "       [ 139.192   ,   37.27838 ],\n",
       "       [  64.6813  ,   39.37738 ],\n",
       "       [ 111.7715  ,   16.23503 ],\n",
       "       [ 130.1085  ,   37.81398 ],\n",
       "       [  64.05415 ,   25.52198 ],\n",
       "       [ 120.5695  ,   29.65138 ],\n",
       "       [  92.535   ,   37.88638 ],\n",
       "       [ 108.1535  ,   22.96703 ],\n",
       "       [  53.7186  ,   15.80243 ],\n",
       "       [  72.8145  ,   24.35993 ],\n",
       "       [  92.702   ,   35.20523 ],\n",
       "       [  96.45135 ,   25.81983 ],\n",
       "       [  66.3013  ,   38.90863 ],\n",
       "       [  38.1808  ,   25.15393 ],\n",
       "       [  77.8025  ,   27.52133 ],\n",
       "       [  92.628   ,   29.67583 ],\n",
       "       [  92.885   ,   31.86118 ],\n",
       "       [  81.81255 ,   18.19063 ],\n",
       "       [ 148.986   ,   46.05153 ],\n",
       "       [  83.261   ,   37.74878 ],\n",
       "       [  80.5948  ,   22.71338 ],\n",
       "       [  31.8318  ,   23.78293 ],\n",
       "       [ 111.3245  ,   21.88668 ],\n",
       "       [ 103.239   ,   22.07788 ],\n",
       "       [ 171.2365  ,   55.26523 ],\n",
       "       [ 136.961   ,   26.93518 ],\n",
       "       [  73.8446  ,   26.92423 ],\n",
       "       [  33.4953  ,   52.95548 ],\n",
       "       [  77.7311  ,   27.26073 ],\n",
       "       [ 105.141   ,   21.40898 ],\n",
       "       [  97.868   ,   33.80928 ],\n",
       "       [  96.623   ,   44.91438 ],\n",
       "       [ 111.51    ,   15.04548 ],\n",
       "       [  59.5124  ,   67.85333 ],\n",
       "       [  56.6484  ,   17.29233 ],\n",
       "       [  64.33085 ,   30.72638 ],\n",
       "       [  25.3268  ,   22.67198 ],\n",
       "       [  96.352   ,   55.47383 ],\n",
       "       [  25.3268  ,   22.67198 ],\n",
       "       [ 104.69    ,   42.10408 ],\n",
       "       [  59.4638  ,   24.70708 ],\n",
       "       [  83.90035 ,   41.45273 ],\n",
       "       [  48.8514  ,   23.80433 ],\n",
       "       [  23.13415 ,   21.81743 ],\n",
       "       [  94.4414  ,   35.95873 ],\n",
       "       [  63.9793  ,   28.67143 ],\n",
       "       [  66.4     ,   39.79603 ],\n",
       "       [  95.873   ,   56.07508 ],\n",
       "       [  99.002   ,   38.67548 ],\n",
       "       [  17.9082  ,   21.06398 ],\n",
       "       [ 127.1265  ,   33.64188 ],\n",
       "       [  98.455   ,   48.98038 ],\n",
       "       [  62.05605 ,   22.03193 ],\n",
       "       [  51.56295 ,   16.10623 ],\n",
       "       [  82.4658  ,   20.58298 ],\n",
       "       [ 112.9515  ,   34.27363 ],\n",
       "       [  93.825   ,   55.66258 ],\n",
       "       [  64.32245 ,   21.06558 ],\n",
       "       [ 117.155   ,   45.70738 ],\n",
       "       [  95.7488  ,   53.14778 ],\n",
       "       [ 113.2775  ,   31.91173 ],\n",
       "       [  75.1012  ,   40.64918 ],\n",
       "       [  98.671   ,   29.16458 ],\n",
       "       [ 105.911   ,   17.42573 ],\n",
       "       [  63.4082  ,   57.69708 ],\n",
       "       [  28.99925 ,   22.60738 ],\n",
       "       [ 105.684   ,   18.39478 ],\n",
       "       [  65.42295 ,   25.84623 ],\n",
       "       [  81.8362  ,   18.96468 ],\n",
       "       [  43.91705 ,   24.43593 ],\n",
       "       [  86.1076  ,   20.43898 ],\n",
       "       [  41.753   ,   26.70818 ],\n",
       "       [ 130.543   ,   40.16788 ],\n",
       "       [ 114.038   ,   36.12573 ],\n",
       "       [  78.45655 ,   32.68833 ],\n",
       "       [  54.62155 ,   16.68968 ],\n",
       "       [  69.76985 ,   35.20798 ],\n",
       "       [  89.7997  ,   37.44448 ],\n",
       "       [  80.8542  ,   22.93918 ],\n",
       "       [  86.64665 ,   22.64303 ],\n",
       "       [  96.565   ,   30.30523 ],\n",
       "       [  83.4736  ,   17.93908 ],\n",
       "       [ 111.388   ,   38.03468 ],\n",
       "       [ 111.918   ,   33.71298 ],\n",
       "       [  64.7795  ,   33.02998 ],\n",
       "       [  59.31085 ,   23.99758 ],\n",
       "       [  94.289   ,   25.03413 ],\n",
       "       [  99.701   ,   48.65388 ],\n",
       "       [  62.41535 ,   59.19318 ],\n",
       "       [  62.5286  ,   38.24408 ],\n",
       "       [ 101.295   ,   43.18628 ],\n",
       "       [  93.06505 ,   42.81338 ],\n",
       "       [  22.3881  ,   22.94128 ],\n",
       "       [  33.7244  ,   50.97368 ],\n",
       "       [ 119.44    ,   71.03298 ],\n",
       "       [ 105.5905  ,   33.13653 ],\n",
       "       [  22.6809  ,   21.63213 ],\n",
       "       [ 116.677   ,   38.61593 ],\n",
       "       [  10.70205 ,   49.01038 ],\n",
       "       [  59.1662  ,   66.19978 ],\n",
       "       [ 119.6175  ,   29.58103 ],\n",
       "       [  92.494   ,   32.89208 ],\n",
       "       [  97.7365  ,   38.22018 ],\n",
       "       [  43.62525 ,   24.39553 ],\n",
       "       [ 118.3835  ,   33.73153 ],\n",
       "       [ 110.2455  ,   28.55383 ],\n",
       "       [ 126.6745  ,   21.82698 ],\n",
       "       [ 113.2975  ,   16.42043 ],\n",
       "       [  74.92555 ,   27.35808 ],\n",
       "       [  84.36025 ,   21.99188 ],\n",
       "       [  82.91015 ,   33.59333 ],\n",
       "       [  86.86375 ,   14.74639 ],\n",
       "       [  64.3843  ,   55.53938 ],\n",
       "       [  91.2497  ,   32.01518 ],\n",
       "       [ 144.5115  ,   44.15473 ],\n",
       "       [  53.21995 ,   14.84793 ],\n",
       "       [  67.9542  ,   26.25378 ],\n",
       "       [ 112.2675  ,   17.86063 ],\n",
       "       [ 110.807   ,   33.00238 ],\n",
       "       [ 103.905   ,   21.23128 ],\n",
       "       [  90.3683  ,   68.59468 ],\n",
       "       [  50.96725 ,   20.15513 ],\n",
       "       [  51.56605 ,   14.95048 ],\n",
       "       [  85.91775 ,   19.83553 ],\n",
       "       [  69.17075 ,   25.80438 ],\n",
       "       [  57.11145 ,   25.56808 ],\n",
       "       [  51.81145 ,   14.65778 ],\n",
       "       [ 140.141   ,   26.74803 ],\n",
       "       [  21.2339  ,   22.21688 ],\n",
       "       [ 102.8534  ,   29.45778 ],\n",
       "       [ 124.216   ,   45.18743 ],\n",
       "       [  83.0242  ,   32.74058 ],\n",
       "       [  99.117   ,   44.08128 ],\n",
       "       [  46.20455 ,   17.79895 ],\n",
       "       [  81.437   ,   20.63738 ],\n",
       "       [  72.8377  ,   26.46088 ],\n",
       "       [  91.9245  ,   61.15983 ],\n",
       "       [  59.2982  ,   67.50788 ],\n",
       "       [  90.4316  ,   68.13193 ],\n",
       "       [ 119.2625  ,   42.13023 ],\n",
       "       [ 122.296   ,   29.88188 ],\n",
       "       [ 103.4365  ,   29.20103 ],\n",
       "       [  94.289   ,   25.03413 ],\n",
       "       [  99.1482  ,   29.65538 ],\n",
       "       [  61.4386  ,   22.38018 ],\n",
       "       [  93.1145  ,   57.14578 ],\n",
       "       [  55.9602  ,   17.34358 ],\n",
       "       [  85.5945  ,   18.38433 ],\n",
       "       [ 122.318   ,   29.87048 ],\n",
       "       [  82.6736  ,   20.26928 ],\n",
       "       [  79.49675 ,   32.30193 ],\n",
       "       [  91.5585  ,   66.45903 ],\n",
       "       [  60.2948  ,   18.87308 ],\n",
       "       [  66.907   ,   28.55158 ],\n",
       "       [  83.50605 ,   20.60228 ],\n",
       "       [  72.4497  ,   39.50318 ],\n",
       "       [  61.77735 ,   60.62503 ],\n",
       "       [ 132.351   ,   27.52883 ],\n",
       "       [  51.30545 ,   16.42518 ],\n",
       "       [ 120.923   ,   66.09168 ],\n",
       "       [  86.7462  ,   27.84933 ],\n",
       "       [  90.40345 ,   67.69078 ],\n",
       "       [  39.5354  ,   24.29188 ],\n",
       "       [  58.0907  ,   41.98333 ],\n",
       "       [  73.2407  ,   32.74508 ],\n",
       "       [  81.10355 ,   16.51768 ],\n",
       "       [ 120.263   ,   68.37703 ],\n",
       "       [  92.301   ,   65.01288 ],\n",
       "       [ 100.10025 ,   29.43583 ],\n",
       "       [  95.81445 ,   36.44608 ],\n",
       "       [  86.65475 ,   18.96673 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4777.3464 - val_loss: 4666.5478\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4615.1263 - val_loss: 4374.3021\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 4160.7385 - val_loss: 3651.5402\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 3224.4922 - val_loss: 2428.9168\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 2000.1538 - val_loss: 1305.3587\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1186.8584 - val_loss: 836.4362\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 834.3085 - val_loss: 599.5525\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 662.4683 - val_loss: 465.3540\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 502.9150 - val_loss: 375.9091\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 443.8366 - val_loss: 322.9721\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 398.8950 - val_loss: 287.5121\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 337.8034 - val_loss: 266.6926\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 321.1424 - val_loss: 248.8089\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 290.4764 - val_loss: 237.8509\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 292.7663 - val_loss: 229.2953\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 283.0630 - val_loss: 221.7383\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 261.3074 - val_loss: 212.2547\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 260.3632 - val_loss: 205.0379\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 257.0650 - val_loss: 198.3831\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 242.4251 - val_loss: 189.6120\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 225.8654 - val_loss: 180.3460\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 220.5203 - val_loss: 174.7211\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 215.4005 - val_loss: 163.4250\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 196.6978 - val_loss: 153.0989\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 192.8765 - val_loss: 147.9937\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 182.2853 - val_loss: 138.3074\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 186.7864 - val_loss: 133.4752\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 175.4404 - val_loss: 129.8464\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 164.7199 - val_loss: 126.6417\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 163.6842 - val_loss: 124.8806\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 161.4973 - val_loss: 121.9339\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 167.2642 - val_loss: 119.3472\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 157.4528 - val_loss: 117.8130\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 147.8448 - val_loss: 117.1876\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 149.2105 - val_loss: 115.1768\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 152.3143 - val_loss: 115.4505\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 146.4416 - val_loss: 113.9682\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 154.7909 - val_loss: 112.2048\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 147.7522 - val_loss: 112.1867\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 145.4089 - val_loss: 108.3640\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 142.8735 - val_loss: 110.8642\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 146.4212 - val_loss: 107.1334\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 141.5749 - val_loss: 105.4734\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 143.7804 - val_loss: 107.1660\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 138.7477 - val_loss: 104.4842\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 136.0784 - val_loss: 105.8979\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 129.2753 - val_loss: 103.0525\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 132.2144 - val_loss: 102.0502\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 132.4943 - val_loss: 101.0219\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 128.3691 - val_loss: 100.6250\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 128.3289 - val_loss: 100.4270\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 130.9413 - val_loss: 99.5142\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 130.0509 - val_loss: 97.6784\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 128.1960 - val_loss: 99.1581\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 118.0902 - val_loss: 96.8528\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 120.7505 - val_loss: 97.4003\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 123.4050 - val_loss: 96.2525\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 124.5064 - val_loss: 94.9569\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 120.5115 - val_loss: 92.6928s: 124.6\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 121.2542 - val_loss: 93.7700\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 126.0244 - val_loss: 91.7574\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 121.0041 - val_loss: 93.6007\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 123.7771 - val_loss: 93.2272\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 116.9890 - val_loss: 91.0517\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 117.0588 - val_loss: 90.1022\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 111.6660 - val_loss: 91.3291\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 116.5102 - val_loss: 88.8171\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 114.3670 - val_loss: 90.6807\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 111.7248 - val_loss: 88.0692\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 115.9332 - val_loss: 88.6104\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 116.9534 - val_loss: 86.2287\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 112.4399 - val_loss: 87.6767\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 109.9540 - val_loss: 87.6781\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 115.2494 - val_loss: 86.2363\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 111.3293 - val_loss: 87.2048\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 110.1200 - val_loss: 85.3411\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 107.0449 - val_loss: 86.4266\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 110.9072 - val_loss: 84.8193\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 109.8743 - val_loss: 86.0608\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 108.2480 - val_loss: 85.4400\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 108.6107 - val_loss: 83.2883\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 106.4960 - val_loss: 84.5453\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 102.5545 - val_loss: 84.2382\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 104.3612 - val_loss: 83.4201\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 113.8526 - val_loss: 83.9688\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 104.3741 - val_loss: 82.5099\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 106.6708 - val_loss: 82.2566\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 110.0533 - val_loss: 83.2057\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 106.2696 - val_loss: 80.6440\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 105.1382 - val_loss: 83.0844\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 103.0856 - val_loss: 79.6526\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 106.0414 - val_loss: 81.7282\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 103.7085 - val_loss: 79.2273\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 108.2645 - val_loss: 80.1057\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 103.0307 - val_loss: 80.3165\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 97.2267 - val_loss: 78.9085\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 108.4084 - val_loss: 79.2875\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 95.3503 - val_loss: 78.7756\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 96.0010 - val_loss: 79.9548\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 99.5321 - val_loss: 78.6180\n",
      "Fold 1\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4676.4231 - val_loss: 4721.5265\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4491.9524 - val_loss: 4402.3135\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 3976.4338 - val_loss: 3617.3210\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 2927.3309 - val_loss: 2346.9597\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1674.4555 - val_loss: 1313.3380\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1019.5113 - val_loss: 941.0874 1033.\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 755.1376 - val_loss: 728.5466\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 573.2329 - val_loss: 592.4387\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 475.2119 - val_loss: 483.8743: 474.460\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 414.4794 - val_loss: 419.4923\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 358.6584 - val_loss: 370.9761\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 336.5615 - val_loss: 340.1924\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 306.3814 - val_loss: 318.5073\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 290.9015 - val_loss: 298.2811\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 275.8098 - val_loss: 285.2539\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 270.9178 - val_loss: 276.3079\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 265.4021 - val_loss: 263.1584\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 252.5582 - val_loss: 253.9628\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 241.9853 - val_loss: 241.9213\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 224.9612 - val_loss: 230.7807\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 222.1792 - val_loss: 220.9640\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 212.2375 - val_loss: 209.9958\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 210.6401 - val_loss: 205.5272\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 196.5771 - val_loss: 194.4383\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 186.9458 - val_loss: 186.3119\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 184.1062 - val_loss: 180.4938\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 180.2825 - val_loss: 175.0937\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 173.5540 - val_loss: 167.5212\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 160.0902 - val_loss: 164.0611\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 167.4423 - val_loss: 164.3097\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 159.7965 - val_loss: 162.4870\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 167.4390 - val_loss: 160.7207\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 156.7201 - val_loss: 156.8291\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 158.6771 - val_loss: 152.5361\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 151.6756 - val_loss: 153.0138\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 149.7086 - val_loss: 148.2298\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 151.5227 - val_loss: 148.6881\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 154.9822 - val_loss: 144.2872\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 150.0431 - val_loss: 145.2017\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 139.6800 - val_loss: 143.5086\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 143.2263 - val_loss: 142.7397\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 146.6092 - val_loss: 142.2812\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 140.7092 - val_loss: 140.3667\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 135.6347 - val_loss: 136.6557\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 141.7729 - val_loss: 135.4477\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 128.2954 - val_loss: 135.8817\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 130.5845 - val_loss: 133.8247\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 132.3539 - val_loss: 132.6628\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 129.9863 - val_loss: 133.4066\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 138.5863 - val_loss: 132.1739\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 126.0837 - val_loss: 130.4878\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 121.8913 - val_loss: 127.8348\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 129.7443 - val_loss: 129.0338\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 125.8029 - val_loss: 128.3014\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 130.1785 - val_loss: 132.3370\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 122.4447 - val_loss: 124.6579\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 125.6005 - val_loss: 127.4243\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 128.7499 - val_loss: 124.5475\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 122.6077 - val_loss: 125.6497\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 126.8322 - val_loss: 126.2716\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 123.4066 - val_loss: 120.8575\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 114.5990 - val_loss: 121.4469\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 124.7389 - val_loss: 120.9295\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 118.6503 - val_loss: 124.0963\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 126.3023 - val_loss: 123.0012\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 121.9594 - val_loss: 120.6124\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 118.5844 - val_loss: 118.5320\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 111.6703 - val_loss: 114.8603\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 111.9503 - val_loss: 117.0349\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 114.2023 - val_loss: 118.2069\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 110.6983 - val_loss: 116.6055\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 118.6290 - val_loss: 118.5631\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 114.9706 - val_loss: 112.4264\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 116.6681 - val_loss: 114.6774\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 111.0338 - val_loss: 112.0871\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 119.1375 - val_loss: 115.4237\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 110.1080 - val_loss: 109.2904\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 110.3939 - val_loss: 111.0794\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 107.5979 - val_loss: 111.0602\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 108.0683 - val_loss: 113.3032\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 108.5117 - val_loss: 109.3439\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 112.0979 - val_loss: 110.0346\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 111.4326 - val_loss: 108.6153\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 111.3650 - val_loss: 110.7227\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 104.2506 - val_loss: 108.9168\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 108.3362 - val_loss: 104.6526\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 105.1433 - val_loss: 104.3176\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 106.5488 - val_loss: 108.2633\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 111.2151 - val_loss: 107.8746\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 111.1467 - val_loss: 107.8292\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 105.0546 - val_loss: 106.8388\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 102.2768 - val_loss: 105.5664\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 107.0485 - val_loss: 114.0970\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 108.3002 - val_loss: 103.2998\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 108.1427 - val_loss: 107.3546\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 101.0504 - val_loss: 103.6289\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 101.6275 - val_loss: 106.0618\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 99.1647 - val_loss: 103.0651\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 106.3803 - val_loss: 98.6206\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 103.7600 - val_loss: 102.6555\n",
      "Fold 2\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4637.0120 - val_loss: 4434.8595\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4451.5490 - val_loss: 4114.1361\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 3935.6636 - val_loss: 3335.3345\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 2918.0557 - val_loss: 2077.2590\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1686.0190 - val_loss: 1057.3464\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1036.1256 - val_loss: 708.4989\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 769.1329 - val_loss: 533.2149\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 603.0065 - val_loss: 417.4608\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 487.6936 - val_loss: 344.7438\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 416.6642 - val_loss: 302.4085\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 380.7769 - val_loss: 273.9833\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 343.2775 - val_loss: 256.5698\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 319.6507 - val_loss: 244.1700\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 292.8157 - val_loss: 232.3929\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 281.1695 - val_loss: 222.2213\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 267.8414 - val_loss: 213.0012\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 253.7576 - val_loss: 205.0508\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 245.8506 - val_loss: 198.1234\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 243.4460 - val_loss: 189.6214\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 233.3633 - val_loss: 181.2660\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 218.7075 - val_loss: 172.8158\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 223.1516 - val_loss: 165.0743\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 206.7859 - val_loss: 155.6992\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 201.6176 - val_loss: 148.2335\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 185.8932 - val_loss: 141.4247\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 180.8827 - val_loss: 134.5629\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 180.7011 - val_loss: 129.4650\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 175.2366 - val_loss: 125.6456\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 163.8680 - val_loss: 122.4690\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 173.1306 - val_loss: 120.0341\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 157.8033 - val_loss: 117.9143\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 158.0351 - val_loss: 116.3650\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 153.4015 - val_loss: 114.9885\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 153.0187 - val_loss: 112.8451\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 150.5996 - val_loss: 111.5054\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 151.1234 - val_loss: 110.8676\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 159.2250 - val_loss: 109.6366\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 144.8121 - val_loss: 108.1829\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 144.0731 - val_loss: 107.4524\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 138.7608 - val_loss: 105.7452\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 139.1464 - val_loss: 104.9639\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 144.6663 - val_loss: 104.2744\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 141.3040 - val_loss: 103.5127\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 134.3189 - val_loss: 102.5368\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 137.1984 - val_loss: 102.2926\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 131.2861 - val_loss: 100.8701\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 137.5157 - val_loss: 100.9771\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 126.2921 - val_loss: 99.9969\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 132.0087 - val_loss: 99.3722\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 130.5766 - val_loss: 99.2534\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 129.1147 - val_loss: 98.7570\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 124.0635 - val_loss: 97.8217\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 122.2873 - val_loss: 98.1957\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 119.7276 - val_loss: 96.4114\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 122.1947 - val_loss: 97.5285\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 117.4420 - val_loss: 96.5557\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 122.8741 - val_loss: 96.1269\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 127.1696 - val_loss: 95.0487\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 115.9469 - val_loss: 94.0817\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 119.7889 - val_loss: 93.4701\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 121.6625 - val_loss: 92.8402\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 115.4014 - val_loss: 92.3000\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 118.2142 - val_loss: 92.5093\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 115.2017 - val_loss: 91.6091\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 112.7682 - val_loss: 91.5549\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 111.2110 - val_loss: 91.0550\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - ETA: 0s - loss: 112.465 - 0s - loss: 113.1965 - val_loss: 90.6455\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 117.5965 - val_loss: 90.2549\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 107.5235 - val_loss: 89.9977\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 116.1462 - val_loss: 90.0246\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 112.3883 - val_loss: 89.3660\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 111.0844 - val_loss: 88.8596\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 112.9701 - val_loss: 88.8933\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 110.1631 - val_loss: 89.0100\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 109.3959 - val_loss: 88.8923\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 108.3407 - val_loss: 87.9927\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 119.2640 - val_loss: 87.8714\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 110.2494 - val_loss: 87.2413\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 109.1631 - val_loss: 86.5483\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 108.2065 - val_loss: 86.4922\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 106.7667 - val_loss: 86.4052\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 109.8633 - val_loss: 87.0238\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 113.8850 - val_loss: 86.1940\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 109.5566 - val_loss: 86.2400\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 107.2513 - val_loss: 85.5119\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 99.4334 - val_loss: 85.6589\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 104.6051 - val_loss: 86.1466\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 101.6805 - val_loss: 84.9988\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 105.6165 - val_loss: 85.5863\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 105.1937 - val_loss: 85.6846\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 103.6464 - val_loss: 84.1960\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 104.0257 - val_loss: 84.3835\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 105.0781 - val_loss: 85.4528\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 104.3600 - val_loss: 85.3914\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 103.3123 - val_loss: 84.9327\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 106.7032 - val_loss: 84.4242\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 103.1351 - val_loss: 84.5572\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 104.3091 - val_loss: 83.6966\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 101.3761 - val_loss: 84.0751\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 96.5722 - val_loss: 83.9702\n",
      "Fold 3\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4709.6781 - val_loss: 4250.6045\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4524.9813 - val_loss: 3924.9562\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 4010.2641 - val_loss: 3153.1374\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 3005.7729 - val_loss: 1956.1612\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1773.7743 - val_loss: 1082.2658\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1100.1465 - val_loss: 802.3756\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 759.8793 - val_loss: 592.3331\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 622.1113 - val_loss: 472.3175\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 489.3426 - val_loss: 396.0553\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 427.6497 - val_loss: 342.4765\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 387.4482 - val_loss: 308.9330\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 350.7308 - val_loss: 283.9339\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 330.6061 - val_loss: 264.5178\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 305.8971 - val_loss: 249.5194\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 292.3087 - val_loss: 239.0030\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 280.8985 - val_loss: 228.1514\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 279.0737 - val_loss: 219.4427\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 263.8911 - val_loss: 210.6761\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 241.9235 - val_loss: 203.0511\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 251.7123 - val_loss: 197.0320\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 240.0488 - val_loss: 186.6044\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 235.6861 - val_loss: 177.6658\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 221.0218 - val_loss: 171.9007\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 210.4496 - val_loss: 162.6002\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 197.9387 - val_loss: 151.8960\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 200.2491 - val_loss: 145.2272\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 187.5054 - val_loss: 136.8147\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 172.0460 - val_loss: 131.7175\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 180.8238 - val_loss: 126.5547\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 176.1883 - val_loss: 122.0357\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 160.5463 - val_loss: 118.5915\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 155.5895 - val_loss: 116.4960\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 158.4575 - val_loss: 115.6655\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 162.6676 - val_loss: 116.1074\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 162.5752 - val_loss: 112.5627\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 156.2357 - val_loss: 115.2606\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 146.1666 - val_loss: 110.1935\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 148.4446 - val_loss: 107.7836\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 149.1567 - val_loss: 106.4044\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 148.0739 - val_loss: 104.8052\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 140.3330 - val_loss: 104.8750\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 135.9040 - val_loss: 104.2274\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 143.3193 - val_loss: 103.8215\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 147.1358 - val_loss: 102.4810\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 136.0403 - val_loss: 100.6496\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 131.0491 - val_loss: 100.9793\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 134.8620 - val_loss: 98.0269\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 134.4415 - val_loss: 98.1471\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 135.7082 - val_loss: 99.1882\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 138.7285 - val_loss: 98.3347\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 124.9216 - val_loss: 97.1232\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 127.8767 - val_loss: 97.5885\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 122.9597 - val_loss: 98.3891\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 124.5958 - val_loss: 96.0980\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 126.6254 - val_loss: 97.4850\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 125.9216 - val_loss: 95.0750\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 128.1593 - val_loss: 94.9425\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 124.7411 - val_loss: 95.1284\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 115.6829 - val_loss: 93.0882\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 126.7898 - val_loss: 94.2046\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 122.0034 - val_loss: 91.6029s: 124.05\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 124.6337 - val_loss: 91.3385\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 120.7171 - val_loss: 90.7528\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 119.4553 - val_loss: 91.5968\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 122.4803 - val_loss: 89.5927\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 114.1556 - val_loss: 90.8167\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 115.3163 - val_loss: 88.8227\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 114.1519 - val_loss: 88.3340\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 120.7073 - val_loss: 88.7865\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 111.8427 - val_loss: 88.1603\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 113.6772 - val_loss: 88.7034\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 111.7287 - val_loss: 89.3404\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 115.5241 - val_loss: 89.4625\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 109.3785 - val_loss: 87.4699\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 113.4468 - val_loss: 89.2187\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 112.7445 - val_loss: 88.0882\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 107.8950 - val_loss: 87.7922\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 109.3301 - val_loss: 85.8051\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 110.3043 - val_loss: 85.6226\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 103.8307 - val_loss: 83.6546\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 103.7618 - val_loss: 84.2262\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 109.4137 - val_loss: 83.6901\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 99.9186 - val_loss: 86.0213\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 105.9976 - val_loss: 85.0217\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 108.5155 - val_loss: 83.0523\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 107.5070 - val_loss: 82.2891\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 107.7398 - val_loss: 85.8556\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 108.8648 - val_loss: 82.4180\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 100.3097 - val_loss: 81.9384\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 106.8842 - val_loss: 81.3129\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 103.9975 - val_loss: 83.4709\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 106.9680 - val_loss: 83.4469\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 102.3246 - val_loss: 82.5297\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 101.0477 - val_loss: 80.6689\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 102.8750 - val_loss: 82.0523\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 102.7465 - val_loss: 81.3162\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 101.7899 - val_loss: 81.4978\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 100.1213 - val_loss: 80.8226\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 102.7198 - val_loss: 80.8510\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 104.7409 - val_loss: 78.7398\n",
      "Fold 4\n",
      "Train on 809 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 0s - loss: 4650.4403 - val_loss: 4522.6079\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 0s - loss: 4459.2535 - val_loss: 4188.3773\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 0s - loss: 3928.9718 - val_loss: 3375.5466\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 0s - loss: 2884.5197 - val_loss: 2083.6368\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 0s - loss: 1639.6576 - val_loss: 1087.5656\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 0s - loss: 1031.2556 - val_loss: 750.5190\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 0s - loss: 722.7252 - val_loss: 531.5892\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 0s - loss: 572.0218 - val_loss: 412.9575\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 0s - loss: 467.7418 - val_loss: 337.6042\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 0s - loss: 413.7111 - val_loss: 292.5116\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 0s - loss: 365.5997 - val_loss: 263.9279\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 0s - loss: 332.8336 - val_loss: 243.2644\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 0s - loss: 322.3670 - val_loss: 229.2383\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 0s - loss: 296.5000 - val_loss: 220.2732\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 0s - loss: 287.3002 - val_loss: 212.8827\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 0s - loss: 273.3002 - val_loss: 206.8574\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 0s - loss: 267.3385 - val_loss: 199.8992\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 0s - loss: 259.1926 - val_loss: 195.0214\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 0s - loss: 245.6107 - val_loss: 188.1710\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 0s - loss: 243.2391 - val_loss: 182.5982\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 0s - loss: 237.9168 - val_loss: 177.8018\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 0s - loss: 224.9301 - val_loss: 171.1621\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 0s - loss: 218.1220 - val_loss: 163.1989\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 0s - loss: 219.9739 - val_loss: 155.6321\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 0s - loss: 211.7702 - val_loss: 146.2712\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 0s - loss: 193.4843 - val_loss: 139.0008\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 0s - loss: 184.2495 - val_loss: 132.1818\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 0s - loss: 186.2672 - val_loss: 131.6475\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 0s - loss: 172.9915 - val_loss: 122.3979\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 0s - loss: 171.3344 - val_loss: 117.8667\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 0s - loss: 173.8525 - val_loss: 118.8498\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 0s - loss: 163.5169 - val_loss: 112.6921\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 0s - loss: 155.1389 - val_loss: 112.2153\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 0s - loss: 153.2524 - val_loss: 109.5566\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 0s - loss: 153.7968 - val_loss: 109.7061\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 0s - loss: 149.9165 - val_loss: 107.7302\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 0s - loss: 152.5239 - val_loss: 106.8534\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 0s - loss: 140.3891 - val_loss: 104.8888\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 0s - loss: 145.6881 - val_loss: 106.1447\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 0s - loss: 150.0947 - val_loss: 103.3917\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 0s - loss: 146.5828 - val_loss: 104.5187\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 0s - loss: 140.9168 - val_loss: 101.8321\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 0s - loss: 135.0133 - val_loss: 99.4159\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 0s - loss: 138.8473 - val_loss: 99.6965\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 0s - loss: 137.2643 - val_loss: 100.0273\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 0s - loss: 138.8525 - val_loss: 99.6506\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 0s - loss: 134.7358 - val_loss: 98.6127\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 0s - loss: 137.2274 - val_loss: 96.5080\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 0s - loss: 130.9092 - val_loss: 97.5737\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 0s - loss: 128.8185 - val_loss: 96.1043\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 0s - loss: 130.2814 - val_loss: 95.1018\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 0s - loss: 133.2009 - val_loss: 95.7796\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 0s - loss: 129.7578 - val_loss: 93.4771\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 0s - loss: 130.2399 - val_loss: 96.0287\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 0s - loss: 127.3680 - val_loss: 92.3663\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 0s - loss: 123.0279 - val_loss: 91.4170\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 0s - loss: 123.2649 - val_loss: 93.4111\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 0s - loss: 131.1411 - val_loss: 91.6329\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 0s - loss: 123.4449 - val_loss: 91.2654\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 0s - loss: 122.6508 - val_loss: 90.8879\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 0s - loss: 117.1049 - val_loss: 90.1483\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 0s - loss: 119.8105 - val_loss: 90.9730\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 0s - loss: 121.8904 - val_loss: 89.5211\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 0s - loss: 123.2766 - val_loss: 89.7943\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 0s - loss: 119.2634 - val_loss: 89.4897\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 0s - loss: 123.4112 - val_loss: 89.8986\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 0s - loss: 118.7154 - val_loss: 87.9952\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 0s - loss: 120.7015 - val_loss: 89.3009\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 0s - loss: 122.5058 - val_loss: 88.7444\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 0s - loss: 116.8746 - val_loss: 88.4107\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 0s - loss: 118.4070 - val_loss: 85.9921\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 0s - loss: 116.1782 - val_loss: 87.1973\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 0s - loss: 117.4481 - val_loss: 86.4834\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 0s - loss: 113.9049 - val_loss: 85.9100\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 0s - loss: 115.1180 - val_loss: 84.4811\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 0s - loss: 112.1377 - val_loss: 87.9868\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 0s - loss: 110.9738 - val_loss: 85.4326\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 0s - loss: 112.8737 - val_loss: 88.3743\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 0s - loss: 110.9743 - val_loss: 84.4804\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 0s - loss: 107.3323 - val_loss: 84.1637\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 0s - loss: 108.9465 - val_loss: 84.5915\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 0s - loss: 109.8669 - val_loss: 86.8920\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 0s - loss: 114.1872 - val_loss: 83.8452s: 109.0\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 0s - loss: 112.8113 - val_loss: 85.6391\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 0s - loss: 111.4564 - val_loss: 83.1195\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 0s - loss: 106.4436 - val_loss: 83.7267\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 0s - loss: 105.1663 - val_loss: 83.8707\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 0s - loss: 107.5322 - val_loss: 85.0731\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 0s - loss: 104.5767 - val_loss: 83.5155\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 0s - loss: 104.7858 - val_loss: 83.9753\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 0s - loss: 106.7679 - val_loss: 81.1845\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 0s - loss: 105.6722 - val_loss: 82.9552\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 0s - loss: 104.0990 - val_loss: 82.8101\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 0s - loss: 108.9281 - val_loss: 81.7379\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 0s - loss: 103.2119 - val_loss: 81.8100\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 0s - loss: 105.3074 - val_loss: 82.5037\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 0s - loss: 100.3989 - val_loss: 82.4343\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 0s - loss: 104.6783 - val_loss: 81.7168\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 0s - loss: 103.0448 - val_loss: 82.1911 101.17\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 0s - loss: 103.2143 - val_loss: 80.7529\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\notebooks\\indoor position\\auto_regression.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_dim=992, activation=\"relu\", use_bias=True)`\n",
      "  model.add(Dense(512, input_dim=input_size, activation='relu', bias=True))\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\notebooks\\indoor position\\auto_regression.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", use_bias=True)`\n",
      "  model.add(Dense(256, activation='relu', bias=True))\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\notebooks\\indoor position\\auto_regression.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_dim=256, activation=\"relu\", use_bias=True)`\n",
      "  e.add(Dense(512, input_dim=256, activation='relu', bias=True))\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\notebooks\\indoor position\\auto_regression.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(992, activation=\"relu\", use_bias=True)`\n",
      "  e.add(Dense(input_size, activation='relu', bias=True))\n",
      "C:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     - ETA: 0s - loss: 0.00\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4599.0483 - val_loss: 4727.5965\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 2771.1180 - val_loss: 1323.8278\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 905.7628 - val_loss: 537.1475\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 426.1615 - val_loss: 283.8729\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 342.4308 - val_loss: 207.1309\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 311.8616 - val_loss: 186.6410\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 288.9723 - val_loss: 206.8581\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 247.0506 - val_loss: 168.2950\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 252.2409 - val_loss: 177.7396\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 248.2021 - val_loss: 164.3128\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 253.2141 - val_loss: 156.8278\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 239.1239 - val_loss: 151.9722\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 211.2243 - val_loss: 158.5208\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 220.4700 - val_loss: 165.4475\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 210.0704 - val_loss: 144.3487\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 190.4738 - val_loss: 151.4702\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 178.9415 - val_loss: 118.9380\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 160.2784 - val_loss: 82.1262\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 135.9468 - val_loss: 74.5202\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 143.2331 - val_loss: 98.0281\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 124.5856 - val_loss: 79.8227\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 120.8977 - val_loss: 83.4277\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 117.4186 - val_loss: 68.6226\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 121.4347 - val_loss: 83.8345\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 121.0946 - val_loss: 59.9228\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 131.8762 - val_loss: 57.7632\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 115.4978 - val_loss: 86.8603\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 115.2187 - val_loss: 68.1897\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 122.5221 - val_loss: 67.5108\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 109.3461 - val_loss: 93.5383\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 115.3777 - val_loss: 61.2295\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 103.9452 - val_loss: 68.8329\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 104.2205 - val_loss: 68.6056\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 106.9000 - val_loss: 69.8890\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 100.3734 - val_loss: 62.3390\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 102.3878 - val_loss: 57.4365\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 101.0399 - val_loss: 59.6989\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 110.9678 - val_loss: 58.3619\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 99.4919 - val_loss: 67.4225\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 101.0777 - val_loss: 64.8506\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 106.3024 - val_loss: 57.4167\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 93.7595 - val_loss: 107.0810\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 99.9950 - val_loss: 57.8295\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 100.8710 - val_loss: 54.5974\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 101.5687 - val_loss: 73.2926\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 103.3659 - val_loss: 74.6386\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 94.4004 - val_loss: 62.6097ss: 100.2\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 93.5564 - val_loss: 64.1760\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 103.2564 - val_loss: 57.7040\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 100.7459 - val_loss: 62.8198\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 97.2139 - val_loss: 50.9900\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 104.3279 - val_loss: 81.3085\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 98.3601 - val_loss: 61.5072\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 103.9937 - val_loss: 60.2898\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 99.9068 - val_loss: 77.1869\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 99.6921 - val_loss: 64.3611\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 98.5951 - val_loss: 75.4149\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 90.9230 - val_loss: 56.9653\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 87.7147 - val_loss: 88.1890\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 99.3907 - val_loss: 49.8793\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 90.8686 - val_loss: 62.5519\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 114.6997 - val_loss: 94.3838\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 91.7156 - val_loss: 60.8588\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 93.4634 - val_loss: 56.4078\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 85.1460 - val_loss: 68.6343\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 109.9736 - val_loss: 78.5867\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 93.2861 - val_loss: 57.9367\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 92.7854 - val_loss: 74.6674\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 91.4089 - val_loss: 66.4943\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 88.8320 - val_loss: 79.8841\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 92.6737 - val_loss: 63.4541\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 93.6732 - val_loss: 55.7969\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 92.8967 - val_loss: 76.7425\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 87.2272 - val_loss: 54.3134\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 100.3867 - val_loss: 78.4370\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 104.0190 - val_loss: 57.1113\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 85.1250 - val_loss: 83.2124\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 108.1986 - val_loss: 74.5238\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 111.1575 - val_loss: 55.8442\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 87.4042 - val_loss: 65.9986\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 86.7618 - val_loss: 91.3961\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 98.8387 - val_loss: 58.4783\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 87.1852 - val_loss: 56.1027\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 84.2622 - val_loss: 65.6647\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 89.6200 - val_loss: 54.8522\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 90.5386 - val_loss: 51.2579\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 84.9917 - val_loss: 84.4006\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 88.1670 - val_loss: 57.4826\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 85.5560 - val_loss: 57.6387\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 85.1102 - val_loss: 61.2588\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 89.7894 - val_loss: 55.0619\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 90.8654 - val_loss: 67.0888\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 85.8840 - val_loss: 58.5155\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 82.7412 - val_loss: 56.9316\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 87.8558 - val_loss: 57.7730\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 85.7935 - val_loss: 73.9454\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 90.2520 - val_loss: 69.3760\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 88.4283 - val_loss: 54.1372\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 83.7642 - val_loss: 79.4938\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 100.3640 - val_loss: 52.0625\n",
      "Fold 1\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4645.6552 - val_loss: 4322.2481\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 2814.8908 - val_loss: 1323.3175\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 910.6481 - val_loss: 530.5915\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 438.5227 - val_loss: 262.0196\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 357.5819 - val_loss: 200.1380\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 320.2751 - val_loss: 193.0943\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 299.7861 - val_loss: 182.8041\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 271.5401 - val_loss: 176.0920\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 265.5051 - val_loss: 171.1758\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 251.7810 - val_loss: 168.5035\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 239.0011 - val_loss: 161.2663\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 248.0630 - val_loss: 168.0498\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 232.3816 - val_loss: 152.5791\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 213.3166 - val_loss: 139.0944\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 204.4262 - val_loss: 123.5278\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 190.1867 - val_loss: 96.5197\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 160.2344 - val_loss: 89.5267\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 150.4270 - val_loss: 80.2413\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 138.1034 - val_loss: 90.2035\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 129.6706 - val_loss: 78.2998\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 132.6874 - val_loss: 79.7599\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 130.6839 - val_loss: 65.8902\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 122.2925 - val_loss: 65.9771\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 126.4574 - val_loss: 65.3193\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 108.8140 - val_loss: 64.7331\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 124.7233 - val_loss: 67.6257\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 107.4314 - val_loss: 78.2264\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 111.4248 - val_loss: 65.3412\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 110.6235 - val_loss: 84.5825\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 108.0297 - val_loss: 64.4496\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 107.1852 - val_loss: 61.1091\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 103.6724 - val_loss: 88.1334\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 103.9760 - val_loss: 89.4329\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 118.4292 - val_loss: 62.6703\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 119.2882 - val_loss: 70.4255\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 103.9410 - val_loss: 65.4904\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 104.8986 - val_loss: 61.6878\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 106.4546 - val_loss: 70.2016\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 107.0042 - val_loss: 58.6369\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 106.8793 - val_loss: 74.6528\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 97.7860 - val_loss: 63.9112\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 99.1008 - val_loss: 55.8881\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 97.8043 - val_loss: 64.0383\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 94.2646 - val_loss: 56.3939\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 113.1551 - val_loss: 54.2502\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 106.8133 - val_loss: 66.0724\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 103.4030 - val_loss: 68.7067\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 91.9008 - val_loss: 56.3245\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 103.4652 - val_loss: 68.1661\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 102.4583 - val_loss: 55.8189\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 87.7556 - val_loss: 68.8285\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 93.7713 - val_loss: 56.8726\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 89.4918 - val_loss: 77.5480\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 97.4505 - val_loss: 53.3333\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 100.8536 - val_loss: 58.4388\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 93.0965 - val_loss: 61.9953\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 96.8053 - val_loss: 86.9101\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 101.2661 - val_loss: 51.3058\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 100.3947 - val_loss: 55.0362\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 90.4581 - val_loss: 57.3039\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 87.7405 - val_loss: 59.9442\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 88.1334 - val_loss: 49.8535\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 80.9310 - val_loss: 53.8439\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 86.9582 - val_loss: 50.9301\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 85.1209 - val_loss: 53.1494\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 81.0820 - val_loss: 61.3094\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 95.9341 - val_loss: 52.1821\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 91.4801 - val_loss: 58.7707\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 89.6574 - val_loss: 64.1615\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 88.7012 - val_loss: 62.3049\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 88.8880 - val_loss: 51.3378\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 89.0777 - val_loss: 64.9476\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 83.3095 - val_loss: 53.1562\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 85.0869 - val_loss: 56.1819\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 87.3044 - val_loss: 56.5265\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 88.3654 - val_loss: 96.4712\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 88.0000 - val_loss: 66.5984\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 86.6294 - val_loss: 56.0940\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 87.2232 - val_loss: 55.2021\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 97.8015 - val_loss: 113.3373\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 105.2991 - val_loss: 53.4948\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 86.4766 - val_loss: 69.8024\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 77.1175 - val_loss: 57.0329\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 88.4452 - val_loss: 66.4085\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 96.5439 - val_loss: 53.9556\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 84.0816 - val_loss: 50.2587\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 85.2520 - val_loss: 60.1797\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 84.3606 - val_loss: 50.3969\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 82.5506 - val_loss: 56.2207\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 82.6201 - val_loss: 60.0455\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 104.8574 - val_loss: 69.2904\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 86.7090 - val_loss: 56.4202\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 81.0072 - val_loss: 52.4398\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 79.2432 - val_loss: 55.0522\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 85.9722 - val_loss: 54.0749\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 83.0357 - val_loss: 74.9854\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 87.5259 - val_loss: 57.5003\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 92.7801 - val_loss: 61.5882\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 96.2836 - val_loss: 71.5748\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 88.4862 - val_loss: 54.3189\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4487.6168 - val_loss: 4174.4904\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 2451.0623 - val_loss: 1518.9939\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 806.6792 - val_loss: 524.2530\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 410.0690 - val_loss: 260.2454\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 324.3977 - val_loss: 216.7564\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 273.8824 - val_loss: 200.7612\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 263.9072 - val_loss: 211.9519\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 250.4559 - val_loss: 212.9250\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 252.6413 - val_loss: 184.1915\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 241.1032 - val_loss: 172.7916\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 229.9601 - val_loss: 173.3016\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 237.1545 - val_loss: 205.1043\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 230.3170 - val_loss: 167.7250\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 210.5408 - val_loss: 157.2088\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 207.7660 - val_loss: 148.5735\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 186.9923 - val_loss: 129.0378\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 162.7389 - val_loss: 102.5148\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 158.0842 - val_loss: 95.5736\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 129.6400 - val_loss: 92.3080\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 132.6039 - val_loss: 76.7909\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 126.3598 - val_loss: 78.3979\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 119.6486 - val_loss: 85.3492\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 114.9310 - val_loss: 77.7518\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 119.9008 - val_loss: 63.9112\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 107.6868 - val_loss: 64.4461\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 117.6715 - val_loss: 64.2469\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 112.4693 - val_loss: 62.7072\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 105.9043 - val_loss: 66.3640\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 109.2153 - val_loss: 80.1756\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 102.9644 - val_loss: 67.2366\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 102.6798 - val_loss: 68.6347\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 110.4121 - val_loss: 64.2093\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 105.2062 - val_loss: 69.8592\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 101.2398 - val_loss: 79.9082\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 110.8085 - val_loss: 104.9073\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 111.5754 - val_loss: 67.9623\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 103.1775 - val_loss: 60.8061\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 100.6381 - val_loss: 60.7140\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 98.0257 - val_loss: 80.4383\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 102.6350 - val_loss: 65.0084\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 92.9120 - val_loss: 62.2212\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 91.1052 - val_loss: 63.4077\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 94.1720 - val_loss: 65.4667\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 96.8091 - val_loss: 60.0494\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 101.7698 - val_loss: 60.4247\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 89.3291 - val_loss: 70.0481\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 98.1432 - val_loss: 58.3244\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 91.0027 - val_loss: 55.9371\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 98.2866 - val_loss: 51.5320\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 108.5876 - val_loss: 55.8461\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 93.3391 - val_loss: 59.4535\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 94.0481 - val_loss: 58.3312\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 97.7376 - val_loss: 66.7414\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 87.5706 - val_loss: 53.7968\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 88.1524 - val_loss: 69.4285\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 93.8574 - val_loss: 54.6302\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 93.0634 - val_loss: 69.2047\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 95.8499 - val_loss: 66.0072\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 89.1252 - val_loss: 58.0737\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 87.8740 - val_loss: 56.0167\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 89.5915 - val_loss: 78.3242\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 94.0986 - val_loss: 53.9031\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 88.1820 - val_loss: 54.4839\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 82.1089 - val_loss: 57.8097\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 84.6270 - val_loss: 63.3674\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 87.7086 - val_loss: 53.3698\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 88.3616 - val_loss: 66.7927\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 92.2728 - val_loss: 71.9750\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 90.6536 - val_loss: 57.3318\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 89.1288 - val_loss: 52.4110\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 75.4277 - val_loss: 60.7301\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 85.1730 - val_loss: 61.0227\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 79.7826 - val_loss: 64.5998\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 87.9797 - val_loss: 79.7692\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 86.2058 - val_loss: 55.5946\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 86.0748 - val_loss: 49.5013\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 93.2037 - val_loss: 53.0708\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 77.2820 - val_loss: 56.1129\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 81.4522 - val_loss: 58.0558\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 87.5359 - val_loss: 62.2791\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 80.3018 - val_loss: 58.9041\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 87.0675 - val_loss: 61.5093\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 89.1337 - val_loss: 50.5313\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 82.6980 - val_loss: 54.9164\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 86.6522 - val_loss: 59.9609\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 85.3190 - val_loss: 60.2442\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 85.6572 - val_loss: 52.4319\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 81.2426 - val_loss: 53.4177\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 78.3016 - val_loss: 64.3446\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 89.9316 - val_loss: 56.8051\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 89.6854 - val_loss: 70.1740\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 78.7956 - val_loss: 55.7158\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 83.6081 - val_loss: 65.5572\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 74.7196 - val_loss: 53.1857\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 88.5510 - val_loss: 96.1625\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 87.4002 - val_loss: 54.5506\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 82.4974 - val_loss: 55.7868\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 79.3181 - val_loss: 48.8649\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 74.3031 - val_loss: 65.7658\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 89.4634 - val_loss: 58.0481\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     - ETA: 0s - loss: 0.\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     - ETA: 0s - loss: 0.00\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 0.0010     \n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4583.9781 - val_loss: 4119.7284\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 2606.4837 - val_loss: 1318.2881\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 890.0450 - val_loss: 463.1195\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 451.5510 - val_loss: 312.6843\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 332.8724 - val_loss: 206.4742\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 300.7025 - val_loss: 192.3757\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 279.5620 - val_loss: 197.7781\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 265.4390 - val_loss: 184.1062\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 249.5995 - val_loss: 181.4159\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 249.6730 - val_loss: 178.1892\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 230.9144 - val_loss: 173.0794\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 219.6459 - val_loss: 164.6534\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 221.3389 - val_loss: 163.8772\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 209.7555 - val_loss: 155.7859\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 213.2229 - val_loss: 159.2985\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 200.0636 - val_loss: 144.1638\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 199.6898 - val_loss: 133.7229\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 181.5361 - val_loss: 117.0502\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 169.4256 - val_loss: 92.2293\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 145.8818 - val_loss: 82.5478\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 129.1562 - val_loss: 72.0139\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 126.4241 - val_loss: 69.0198\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 131.4571 - val_loss: 69.9338\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 120.6646 - val_loss: 67.3213\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 107.8346 - val_loss: 67.3332\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 120.2081 - val_loss: 64.6668\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 117.3310 - val_loss: 79.3939\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 113.0851 - val_loss: 66.8264\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 108.1405 - val_loss: 65.3213\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 103.7322 - val_loss: 63.6771\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 102.6305 - val_loss: 69.3321 101.762\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 111.6659 - val_loss: 87.5124\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 94.5498 - val_loss: 71.2335\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 115.9514 - val_loss: 60.6195\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 95.0610 - val_loss: 61.0563\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 101.1099 - val_loss: 63.3709\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 103.5952 - val_loss: 75.9008\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 103.8164 - val_loss: 56.8679\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 101.5803 - val_loss: 57.5860\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 95.4748 - val_loss: 65.0269\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 90.5881 - val_loss: 60.4527\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 88.6808 - val_loss: 69.0668\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 95.3701 - val_loss: 61.2893\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 100.5622 - val_loss: 64.7565\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 99.3087 - val_loss: 60.4954\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 90.3171 - val_loss: 61.0062\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 87.0114 - val_loss: 57.6958\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 93.9345 - val_loss: 80.2940\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 95.0559 - val_loss: 55.6082\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 90.1416 - val_loss: 53.7484\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 93.7834 - val_loss: 82.4424\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 92.8407 - val_loss: 60.5760\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 84.7342 - val_loss: 57.4620\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 83.4781 - val_loss: 66.1764\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 89.6587 - val_loss: 64.0963\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 84.3119 - val_loss: 68.8674\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 92.6157 - val_loss: 62.1461\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 107.0049 - val_loss: 61.2380\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 93.8040 - val_loss: 68.4291\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 91.9527 - val_loss: 59.4050\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 93.8933 - val_loss: 76.8544\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 87.6506 - val_loss: 64.0139\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 93.1191 - val_loss: 62.9552\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 85.5300 - val_loss: 57.1151\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 83.2410 - val_loss: 66.3321\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 95.4549 - val_loss: 57.7488\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 82.6927 - val_loss: 65.0193\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 79.8194 - val_loss: 69.1138\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 82.7655 - val_loss: 58.4551\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 85.1601 - val_loss: 56.5841\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 86.6842 - val_loss: 56.7508\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 80.5366 - val_loss: 54.4983\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 84.8260 - val_loss: 57.6932\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 79.5679 - val_loss: 57.6901\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 82.7008 - val_loss: 54.9335\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 84.9906 - val_loss: 54.1890\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 78.6728 - val_loss: 55.2892\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 81.6501 - val_loss: 55.0982\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 77.0953 - val_loss: 54.5369\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 77.3413 - val_loss: 56.2356\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 86.9881 - val_loss: 69.0920\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 89.2648 - val_loss: 62.1379\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 81.2855 - val_loss: 60.8510\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 83.4453 - val_loss: 57.3221\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 77.2440 - val_loss: 64.1064\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 82.9985 - val_loss: 54.4985\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 75.2460 - val_loss: 54.8480\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 77.1856 - val_loss: 56.2316\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 73.5846 - val_loss: 55.1023\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 78.3751 - val_loss: 56.4616\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 79.7611 - val_loss: 56.5056\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 80.4859 - val_loss: 59.9270\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 77.1529 - val_loss: 73.6007\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 79.9097 - val_loss: 54.9305\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 76.3870 - val_loss: 62.8606\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 74.0581 - val_loss: 53.6510\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 80.6636 - val_loss: 59.6086\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 72.2430 - val_loss: 58.2451\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 75.6455 - val_loss: 63.4945\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 81.3536 - val_loss: 56.1667\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     - ETA: 0s - loss: 0.\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 0s - loss: 0.0010     \n",
      "Train on 809 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 0s - loss: 4599.0658 - val_loss: 4363.1494\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 0s - loss: 2948.9105 - val_loss: 1308.5914\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 0s - loss: 1011.2824 - val_loss: 770.9971\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 0s - loss: 478.0517 - val_loss: 322.8011\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 0s - loss: 333.6563 - val_loss: 265.8052\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 0s - loss: 311.4445 - val_loss: 262.0811\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 0s - loss: 284.5588 - val_loss: 236.7195\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 0s - loss: 276.4797 - val_loss: 225.2430\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 0s - loss: 250.7592 - val_loss: 219.0615\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 0s - loss: 259.3678 - val_loss: 209.0216\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 0s - loss: 248.3159 - val_loss: 207.4656\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 0s - loss: 244.9864 - val_loss: 207.5316\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 0s - loss: 231.0868 - val_loss: 202.6425\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 0s - loss: 223.2633 - val_loss: 195.2458\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 0s - loss: 207.9481 - val_loss: 199.4688\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 0s - loss: 181.7480 - val_loss: 160.6747\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 0s - loss: 171.8684 - val_loss: 142.7917\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 0s - loss: 149.1683 - val_loss: 113.2880\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 0s - loss: 154.0052 - val_loss: 111.8264\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 0s - loss: 129.9482 - val_loss: 100.8362\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 0s - loss: 141.3486 - val_loss: 107.1002\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 0s - loss: 123.3776 - val_loss: 96.2794\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 0s - loss: 121.8087 - val_loss: 105.7205\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 0s - loss: 128.1922 - val_loss: 110.5878\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 0s - loss: 121.6945 - val_loss: 105.0994\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 0s - loss: 111.3804 - val_loss: 102.5282\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 0s - loss: 111.8516 - val_loss: 104.3329\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 0s - loss: 110.1571 - val_loss: 92.5984\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 0s - loss: 111.5005 - val_loss: 95.4725\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 0s - loss: 110.6834 - val_loss: 97.6374\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 0s - loss: 103.9002 - val_loss: 84.7489\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 0s - loss: 106.5434 - val_loss: 91.1665\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 0s - loss: 104.9660 - val_loss: 95.0706\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 0s - loss: 101.8526 - val_loss: 90.0867\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 0s - loss: 97.7057 - val_loss: 80.1537\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 0s - loss: 107.1945 - val_loss: 82.6443\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 0s - loss: 105.0285 - val_loss: 107.1758\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 0s - loss: 96.0051 - val_loss: 100.7085\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 0s - loss: 97.5682 - val_loss: 91.3555\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 0s - loss: 97.3698 - val_loss: 91.4461\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 0s - loss: 102.1123 - val_loss: 77.8374\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 0s - loss: 98.2447 - val_loss: 86.8086\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 0s - loss: 107.5499 - val_loss: 95.7518\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 0s - loss: 104.0446 - val_loss: 91.6536\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 0s - loss: 104.1071 - val_loss: 112.8939\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 0s - loss: 95.5077 - val_loss: 96.0252\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 0s - loss: 97.4979 - val_loss: 84.6825\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 0s - loss: 97.6086 - val_loss: 101.1530\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 0s - loss: 88.0159 - val_loss: 88.0648\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 0s - loss: 93.9388 - val_loss: 92.1628\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 0s - loss: 93.3310 - val_loss: 92.4324\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 0s - loss: 92.9195 - val_loss: 95.9126\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 0s - loss: 91.0147 - val_loss: 85.2420\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 0s - loss: 90.2166 - val_loss: 85.1868\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 0s - loss: 90.4728 - val_loss: 93.9944\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 0s - loss: 90.1774 - val_loss: 87.4742\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 0s - loss: 86.6949 - val_loss: 82.9847\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 0s - loss: 88.0731 - val_loss: 80.4162\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 0s - loss: 92.9235 - val_loss: 73.1740\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 0s - loss: 95.2845 - val_loss: 102.1292\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 0s - loss: 89.8426 - val_loss: 90.1553\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 0s - loss: 95.5313 - val_loss: 73.2147\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 0s - loss: 88.0567 - val_loss: 83.2190\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 0s - loss: 87.1141 - val_loss: 74.8532\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 0s - loss: 97.7626 - val_loss: 87.2702\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 0s - loss: 110.8111 - val_loss: 83.8675\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 0s - loss: 102.0057 - val_loss: 81.3561\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 0s - loss: 88.5344 - val_loss: 88.0896\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 0s - loss: 95.1152 - val_loss: 88.5331\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 0s - loss: 87.5524 - val_loss: 93.9195\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 0s - loss: 85.7204 - val_loss: 76.7566\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 0s - loss: 90.6883 - val_loss: 86.2555\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 0s - loss: 92.2494 - val_loss: 114.8437\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 0s - loss: 91.8110 - val_loss: 84.8830\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 0s - loss: 92.1240 - val_loss: 100.3668\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 0s - loss: 95.6211 - val_loss: 89.9022\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 0s - loss: 94.7900 - val_loss: 76.5945\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 0s - loss: 86.0841 - val_loss: 97.2909\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 0s - loss: 86.6146 - val_loss: 76.8980\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 0s - loss: 88.1700 - val_loss: 74.5300\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 0s - loss: 89.2529 - val_loss: 91.8704\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 0s - loss: 82.7785 - val_loss: 85.3776\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 0s - loss: 83.9486 - val_loss: 77.9382\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 0s - loss: 89.7953 - val_loss: 98.8193\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 0s - loss: 91.0078 - val_loss: 89.4738\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 0s - loss: 90.9541 - val_loss: 75.1433\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 0s - loss: 87.3132 - val_loss: 96.8870\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 0s - loss: 82.9848 - val_loss: 69.0751\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 0s - loss: 87.3290 - val_loss: 73.3377\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 0s - loss: 93.2157 - val_loss: 103.0877\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 0s - loss: 87.0866 - val_loss: 79.1045\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 0s - loss: 82.2520 - val_loss: 89.4110\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 0s - loss: 81.5541 - val_loss: 76.1006\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 0s - loss: 75.5691 - val_loss: 88.0753\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 0s - loss: 78.5228 - val_loss: 68.8870\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 0s - loss: 103.1134 - val_loss: 73.4057\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 0s - loss: 102.9307 - val_loss: 88.3014\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 0s - loss: 84.5909 - val_loss: 80.6600\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 0s - loss: 89.5684 - val_loss: 91.7694\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 0s - loss: 90.3124 - val_loss: 81.3431\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "blend_train1, blend_test1 = get_oof(clf1, trainX, trainY, testX)\n",
    "blend_train2, blend_test2 = get_oof(clf2, trainX, trainY, testX)\n",
    "blend_train4, blend_test4 = get_oof(clf4, trainX, trainY, testX)\n",
    "blend_train5, blend_test5 = get_oof(clf5, trainX, trainY, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train1 =reshaped(blend_train1)\n",
    "blend_test1 = reshaped(blend_test1)\n",
    "blend_train2 =reshaped(blend_train2)\n",
    "blend_test2 = reshaped(blend_test2)\n",
    "blend_train3 =reshaped(blend_train3)\n",
    "blend_test3 = reshaped(blend_test3)\n",
    "blend_train4 =reshaped(blend_train4)\n",
    "blend_test4 = reshaped(blend_test4)\n",
    "blend_train5 =reshaped(blend_train5)\n",
    "blend_test5 = reshaped(blend_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_trainX = np.column_stack((blend_train1,blend_train2, blend_train3,blend_train4,blend_train5))\n",
    "blend_testX = np.column_stack((blend_test1, blend_test2, blend_test3,blend_test4,blend_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_s = reshaped(trainY)\n",
    "testY_s = reshaped(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.15774421613\n"
     ]
    }
   ],
   "source": [
    "# stacking model 1\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(blend_trainX, trainY_s)\n",
    "pred1 = lr.predict(blend_testX)\n",
    "e, a = accuracy(pred1.reshape((226,2)), testY)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.85795593186\n"
     ]
    }
   ],
   "source": [
    "# stacking model 3\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=4)\n",
    "neigh.fit(blend_trainX, trainY_s)\n",
    "pred3 = neigh.predict(blend_testX)\n",
    "e3, a3 = accuracy(pred3.reshape((226,2)), testY)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <function train_model at 0x0000016E1020A400>\n",
      "Fold 0\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4772.4495 - val_loss: 4640.5937\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4580.5283 - val_loss: 4301.8972\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 4048.7716 - val_loss: 3501.5784\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 3026.3709 - val_loss: 2262.0923\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1826.8906 - val_loss: 1311.9731\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1118.8428 - val_loss: 884.2793\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 783.5000 - val_loss: 644.1486\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 613.6579 - val_loss: 505.8835\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 510.0662 - val_loss: 413.3073\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 442.2402 - val_loss: 357.3569\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 395.9252 - val_loss: 316.3412\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 359.7618 - val_loss: 289.3404\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 332.4323 - val_loss: 270.8572\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 306.5305 - val_loss: 252.9656\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 305.8137 - val_loss: 245.6081\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 292.1738 - val_loss: 232.9654\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 275.9443 - val_loss: 222.5486\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 275.3529 - val_loss: 216.8672\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 254.4975 - val_loss: 206.6164\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 242.2780 - val_loss: 199.9100\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 240.0937 - val_loss: 193.4837\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 218.2296 - val_loss: 183.5675\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 222.3459 - val_loss: 176.3101\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 210.5334 - val_loss: 167.7171\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 209.3445 - val_loss: 161.6821\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 189.3433 - val_loss: 154.2148\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 182.6669 - val_loss: 146.9419\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 182.3186 - val_loss: 145.4749\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 173.2343 - val_loss: 140.4699\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 167.5253 - val_loss: 138.0908\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 162.6557 - val_loss: 134.7784\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 170.9693 - val_loss: 132.7964\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 158.8453 - val_loss: 130.8291\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 155.2656 - val_loss: 127.6101\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 151.1276 - val_loss: 126.5657\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 149.7685 - val_loss: 124.1619\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 154.6614 - val_loss: 126.1565\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 157.5312 - val_loss: 120.2600\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 149.9497 - val_loss: 122.1297\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 143.2656 - val_loss: 119.9666\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 147.8321 - val_loss: 119.6749\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 145.2302 - val_loss: 117.8620\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 141.6195 - val_loss: 115.8962\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 138.3438 - val_loss: 115.5766\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 152.9143 - val_loss: 114.0976\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 137.1759 - val_loss: 116.1346\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 145.6930 - val_loss: 111.0805\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 142.1944 - val_loss: 114.4875\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 136.1762 - val_loss: 111.8426\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 129.9450 - val_loss: 109.3137\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 134.4404 - val_loss: 109.4950\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 126.5326 - val_loss: 107.8841\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 126.5332 - val_loss: 108.6250\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 137.1883 - val_loss: 106.4717\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 121.3208 - val_loss: 109.0949\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 121.8152 - val_loss: 105.7763\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 125.0661 - val_loss: 105.4347\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 126.3727 - val_loss: 104.3404\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 120.6149 - val_loss: 107.0916\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 126.7808 - val_loss: 103.0236\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 123.0569 - val_loss: 103.3583\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 120.6675 - val_loss: 100.2906\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 111.8366 - val_loss: 100.9787\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 123.5391 - val_loss: 101.5257\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 115.1529 - val_loss: 102.2054\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 115.9208 - val_loss: 101.0450\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 117.3973 - val_loss: 99.3585\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 114.4905 - val_loss: 99.9687\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 126.7847 - val_loss: 96.9263\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 112.1303 - val_loss: 101.6268\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 119.7820 - val_loss: 98.1758\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 115.1963 - val_loss: 99.3716\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 106.2991 - val_loss: 94.8566\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 116.1861 - val_loss: 94.0770\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 110.9481 - val_loss: 94.6215\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 111.2224 - val_loss: 92.8053\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 115.2153 - val_loss: 92.3511\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 118.5890 - val_loss: 93.8975\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 106.2785 - val_loss: 92.8464\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 110.7265 - val_loss: 92.8594\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 107.8529 - val_loss: 92.2557\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 111.4620 - val_loss: 92.9608\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 111.1207 - val_loss: 95.4839\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 112.1969 - val_loss: 92.3370\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 108.2908 - val_loss: 90.4180\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 108.6955 - val_loss: 90.5200\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 107.2822 - val_loss: 89.8054\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 109.6533 - val_loss: 89.9213\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 102.1250 - val_loss: 89.6816\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 103.7372 - val_loss: 91.9743\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 105.7120 - val_loss: 87.9380\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 106.4221 - val_loss: 91.4754\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 103.8876 - val_loss: 86.8150\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 104.1479 - val_loss: 84.9420\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 103.8890 - val_loss: 84.2190\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 105.5086 - val_loss: 90.0635\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 104.2573 - val_loss: 85.1193\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 104.9343 - val_loss: 85.8087\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 102.0560 - val_loss: 87.2996\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 101.2841 - val_loss: 88.5339\n",
      "Fold 1\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4667.7040 - val_loss: 4703.0165\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4465.3607 - val_loss: 4351.8697\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 3930.3594 - val_loss: 3535.6204\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 2893.9457 - val_loss: 2248.7289\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1647.0550 - val_loss: 1199.9655\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1024.2495 - val_loss: 865.5656\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 767.8163 - val_loss: 654.8630\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 601.5732 - val_loss: 522.0843\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 482.5824 - val_loss: 420.5019\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 428.4722 - val_loss: 357.7609\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 387.5897 - val_loss: 318.0688\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 357.9018 - val_loss: 289.0264\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 330.3932 - val_loss: 267.2426\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 310.2478 - val_loss: 252.8560\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 296.4046 - val_loss: 242.0721\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 285.2358 - val_loss: 230.7206\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 278.6968 - val_loss: 222.7336\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 273.7382 - val_loss: 212.8038\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 253.9556 - val_loss: 204.2475\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 235.6870 - val_loss: 197.4845\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 241.2457 - val_loss: 187.1947\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 230.3985 - val_loss: 178.5693\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 219.9770 - val_loss: 169.2788\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 213.5371 - val_loss: 159.9852\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 199.2237 - val_loss: 150.8307\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 195.7340 - val_loss: 144.2900\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 183.8086 - val_loss: 137.4144\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 179.4054 - val_loss: 134.0998\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 178.9019 - val_loss: 129.2801\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 160.7407 - val_loss: 126.4414\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 174.9727 - val_loss: 124.9730\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 162.1593 - val_loss: 123.1290\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 164.3505 - val_loss: 121.2228\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 157.8778 - val_loss: 118.9478\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 153.6529 - val_loss: 117.3267\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 147.7329 - val_loss: 115.0530\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 159.6833 - val_loss: 113.6392\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 148.1676 - val_loss: 112.5898\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 142.5814 - val_loss: 111.9792\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 146.3120 - val_loss: 109.8455\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 146.7289 - val_loss: 109.6402\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 139.4747 - val_loss: 108.8552\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 135.3921 - val_loss: 108.1405\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 140.9861 - val_loss: 106.8532\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 133.5303 - val_loss: 105.7965\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 140.8455 - val_loss: 105.1964\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 125.8469 - val_loss: 104.8869\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 137.4922 - val_loss: 105.3078\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 134.5365 - val_loss: 105.4887\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 135.2666 - val_loss: 106.4181\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 131.2552 - val_loss: 105.3327\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 125.4470 - val_loss: 103.9191\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 130.4294 - val_loss: 102.9629\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 129.3433 - val_loss: 102.1881\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 124.6093 - val_loss: 100.8968\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 131.2524 - val_loss: 100.5565\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 129.6080 - val_loss: 100.9115\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 122.8859 - val_loss: 101.0672\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 122.0423 - val_loss: 99.4859\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 127.9640 - val_loss: 98.2821\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 119.8024 - val_loss: 99.4905\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 119.9744 - val_loss: 97.9032\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 120.8982 - val_loss: 97.8996\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 114.8312 - val_loss: 96.7076\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 120.6393 - val_loss: 97.4722\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 118.5525 - val_loss: 96.9715\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 119.8882 - val_loss: 96.2566\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 116.0455 - val_loss: 96.9169\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 110.3638 - val_loss: 96.5894\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 119.3247 - val_loss: 94.0773\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 113.0894 - val_loss: 93.1979\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 114.1282 - val_loss: 93.8057\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 115.5467 - val_loss: 91.9086\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 114.4644 - val_loss: 92.6957\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 115.7478 - val_loss: 91.9154\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 111.0712 - val_loss: 92.5960\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 113.1139 - val_loss: 92.5831\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 114.2932 - val_loss: 91.6535\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 106.5626 - val_loss: 91.4921\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 111.0587 - val_loss: 91.6757\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 107.8344 - val_loss: 91.5114\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 111.7787 - val_loss: 91.5896\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 104.7042 - val_loss: 91.0780\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 106.1407 - val_loss: 91.7440\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 108.7030 - val_loss: 90.9294\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 106.5040 - val_loss: 91.5978\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 113.4763 - val_loss: 89.4336\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 107.3287 - val_loss: 91.4039\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 108.0307 - val_loss: 89.9113\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 109.1342 - val_loss: 89.0300\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 111.6898 - val_loss: 90.6646\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 102.1665 - val_loss: 89.1648\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 100.3341 - val_loss: 89.3472\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 101.8794 - val_loss: 90.6743\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 103.3956 - val_loss: 88.1019\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 110.4989 - val_loss: 90.7075\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 104.1985 - val_loss: 88.7325\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 98.2038 - val_loss: 88.0959\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 101.2244 - val_loss: 87.8376\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 100.7835 - val_loss: 86.6219\n",
      "Fold 2\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4561.4532 - val_loss: 4750.5541\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4392.2985 - val_loss: 4460.7461\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 3938.0222 - val_loss: 3757.0508\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 3005.9386 - val_loss: 2565.0992\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1821.2718 - val_loss: 1430.13382044.\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1104.9248 - val_loss: 941.0561\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 803.7285 - val_loss: 724.3488\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 613.2543 - val_loss: 594.1773\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 524.9068 - val_loss: 481.5924\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 437.9370 - val_loss: 416.8867\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 393.8429 - val_loss: 369.8317\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 366.1070 - val_loss: 337.7902\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 333.9424 - val_loss: 303.6076\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 318.5348 - val_loss: 290.5592\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 290.8840 - val_loss: 267.6768\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 280.4235 - val_loss: 252.0221\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 265.6561 - val_loss: 245.0255\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 268.9152 - val_loss: 231.2394\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 253.1333 - val_loss: 220.8123\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 238.2172 - val_loss: 207.6477\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 228.8043 - val_loss: 194.8839\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 228.8907 - val_loss: 186.1930\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 197.5616 - val_loss: 174.7377\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 189.6827 - val_loss: 164.5114\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 192.3108 - val_loss: 162.3670\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 190.4593 - val_loss: 155.9794\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 175.4367 - val_loss: 151.7502\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 183.7709 - val_loss: 146.3706\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 173.4491 - val_loss: 144.2147\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 167.3455 - val_loss: 141.4658\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 164.0585 - val_loss: 138.5176\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 162.7091 - val_loss: 136.6150\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 159.2024 - val_loss: 139.9483\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 155.4444 - val_loss: 132.2293\n",
      "Epoch 35/100\n",
      "808/808 [==============================] - 0s - loss: 155.2941 - val_loss: 132.5453\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 144.2525 - val_loss: 130.5052\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 148.2325 - val_loss: 130.0585\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 146.4149 - val_loss: 129.1485\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 147.8810 - val_loss: 128.1575\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 142.1051 - val_loss: 124.6401\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 144.7665 - val_loss: 127.9571\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 153.0161 - val_loss: 122.0400\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 146.0846 - val_loss: 124.4153\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 139.7934 - val_loss: 121.0209\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 134.0579 - val_loss: 125.7947\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 134.4913 - val_loss: 118.8272\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 142.6298 - val_loss: 121.0540\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 133.6099 - val_loss: 123.2915\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 130.2103 - val_loss: 118.9706\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 126.8065 - val_loss: 119.6721\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 130.3092 - val_loss: 120.4533\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 130.7512 - val_loss: 115.7854\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 120.5768 - val_loss: 117.2649\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 128.6807 - val_loss: 115.8351\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 127.7445 - val_loss: 113.6157\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 130.4411 - val_loss: 114.6029\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 124.0644 - val_loss: 114.1236\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 120.8488 - val_loss: 112.9613\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 119.9951 - val_loss: 112.3705\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 127.2782 - val_loss: 113.8438\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 122.1985 - val_loss: 114.3501\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 122.8530 - val_loss: 112.8491\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 123.2283 - val_loss: 111.6730\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 117.1869 - val_loss: 111.9229\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 109.7939 - val_loss: 112.3414\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 112.0619 - val_loss: 108.8717\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 111.9464 - val_loss: 110.7687\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 117.7913 - val_loss: 109.7366\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 117.7553 - val_loss: 110.6776\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 110.8256 - val_loss: 108.8364\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 113.2831 - val_loss: 108.8778\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 117.0628 - val_loss: 106.6300\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 115.2681 - val_loss: 107.3921\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 114.3448 - val_loss: 106.4201\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 105.2188 - val_loss: 105.7909\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 109.0645 - val_loss: 105.0423\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 111.4414 - val_loss: 106.6953\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 115.5860 - val_loss: 105.6495\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 110.8976 - val_loss: 104.7265\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 111.1662 - val_loss: 105.9267\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 109.3507 - val_loss: 103.7907\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 107.2699 - val_loss: 106.5498\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 108.2479 - val_loss: 108.5365\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 113.8969 - val_loss: 102.3650\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 103.6714 - val_loss: 103.5086\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 100.1145 - val_loss: 102.3107\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 107.6916 - val_loss: 103.1564\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 101.9172 - val_loss: 104.3078\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 102.4762 - val_loss: 102.4571\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 103.6236 - val_loss: 102.3928\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 103.2239 - val_loss: 103.7197\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 104.1986 - val_loss: 102.5619\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 99.8103 - val_loss: 101.2557\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 104.9861 - val_loss: 102.6072\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 99.9725 - val_loss: 102.9607\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 105.6094 - val_loss: 99.5945\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 107.3039 - val_loss: 103.6705\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 101.2857 - val_loss: 100.9786\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 101.6940 - val_loss: 101.3194\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 101.5891 - val_loss: 99.3880\n",
      "Fold 3\n",
      "Train on 808 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "808/808 [==============================] - 0s - loss: 4659.6294 - val_loss: 4517.3850\n",
      "Epoch 2/100\n",
      "808/808 [==============================] - 0s - loss: 4504.3169 - val_loss: 4256.7005\n",
      "Epoch 3/100\n",
      "808/808 [==============================] - 0s - loss: 4066.7032 - val_loss: 3599.1973\n",
      "Epoch 4/100\n",
      "808/808 [==============================] - 0s - loss: 3145.2579 - val_loss: 2462.0438\n",
      "Epoch 5/100\n",
      "808/808 [==============================] - 0s - loss: 1924.0442 - val_loss: 1363.5372\n",
      "Epoch 6/100\n",
      "808/808 [==============================] - 0s - loss: 1135.2838 - val_loss: 910.5405\n",
      "Epoch 7/100\n",
      "808/808 [==============================] - 0s - loss: 812.2250 - val_loss: 696.6948\n",
      "Epoch 8/100\n",
      "808/808 [==============================] - 0s - loss: 648.1728 - val_loss: 563.7726\n",
      "Epoch 9/100\n",
      "808/808 [==============================] - 0s - loss: 535.6470 - val_loss: 457.1715\n",
      "Epoch 10/100\n",
      "808/808 [==============================] - 0s - loss: 452.1432 - val_loss: 385.3471\n",
      "Epoch 11/100\n",
      "808/808 [==============================] - 0s - loss: 404.8978 - val_loss: 339.7868\n",
      "Epoch 12/100\n",
      "808/808 [==============================] - 0s - loss: 360.6287 - val_loss: 307.8616\n",
      "Epoch 13/100\n",
      "808/808 [==============================] - 0s - loss: 339.9667 - val_loss: 281.7125\n",
      "Epoch 14/100\n",
      "808/808 [==============================] - 0s - loss: 328.0847 - val_loss: 262.0331\n",
      "Epoch 15/100\n",
      "808/808 [==============================] - 0s - loss: 305.9513 - val_loss: 241.8550\n",
      "Epoch 16/100\n",
      "808/808 [==============================] - 0s - loss: 297.7659 - val_loss: 230.4316\n",
      "Epoch 17/100\n",
      "808/808 [==============================] - 0s - loss: 273.6988 - val_loss: 216.2693\n",
      "Epoch 18/100\n",
      "808/808 [==============================] - 0s - loss: 256.7508 - val_loss: 207.9887\n",
      "Epoch 19/100\n",
      "808/808 [==============================] - 0s - loss: 255.0968 - val_loss: 198.9484\n",
      "Epoch 20/100\n",
      "808/808 [==============================] - 0s - loss: 241.5962 - val_loss: 189.8802\n",
      "Epoch 21/100\n",
      "808/808 [==============================] - 0s - loss: 231.3172 - val_loss: 179.4572\n",
      "Epoch 22/100\n",
      "808/808 [==============================] - 0s - loss: 226.9230 - val_loss: 173.6735\n",
      "Epoch 23/100\n",
      "808/808 [==============================] - 0s - loss: 212.9660 - val_loss: 164.6026\n",
      "Epoch 24/100\n",
      "808/808 [==============================] - 0s - loss: 202.2192 - val_loss: 157.4175\n",
      "Epoch 25/100\n",
      "808/808 [==============================] - 0s - loss: 198.9920 - val_loss: 148.1431\n",
      "Epoch 26/100\n",
      "808/808 [==============================] - 0s - loss: 182.9888 - val_loss: 141.6970\n",
      "Epoch 27/100\n",
      "808/808 [==============================] - 0s - loss: 182.3726 - val_loss: 137.9063\n",
      "Epoch 28/100\n",
      "808/808 [==============================] - 0s - loss: 179.8147 - val_loss: 137.3593\n",
      "Epoch 29/100\n",
      "808/808 [==============================] - 0s - loss: 162.8733 - val_loss: 129.8383\n",
      "Epoch 30/100\n",
      "808/808 [==============================] - 0s - loss: 168.9573 - val_loss: 128.2208: 173.95 - ETA: 0s - loss: 171.222\n",
      "Epoch 31/100\n",
      "808/808 [==============================] - 0s - loss: 166.8833 - val_loss: 126.7105\n",
      "Epoch 32/100\n",
      "808/808 [==============================] - 0s - loss: 166.9809 - val_loss: 125.3909\n",
      "Epoch 33/100\n",
      "808/808 [==============================] - 0s - loss: 163.0879 - val_loss: 124.6523\n",
      "Epoch 34/100\n",
      "808/808 [==============================] - 0s - loss: 158.2623 - val_loss: 120.2279\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s - loss: 157.6064 - val_loss: 122.5402\n",
      "Epoch 36/100\n",
      "808/808 [==============================] - 0s - loss: 151.4503 - val_loss: 117.0512\n",
      "Epoch 37/100\n",
      "808/808 [==============================] - 0s - loss: 143.3432 - val_loss: 116.4519\n",
      "Epoch 38/100\n",
      "808/808 [==============================] - 0s - loss: 145.5523 - val_loss: 115.8898\n",
      "Epoch 39/100\n",
      "808/808 [==============================] - 0s - loss: 152.8682 - val_loss: 114.5363\n",
      "Epoch 40/100\n",
      "808/808 [==============================] - 0s - loss: 152.9077 - val_loss: 111.6395\n",
      "Epoch 41/100\n",
      "808/808 [==============================] - 0s - loss: 144.2571 - val_loss: 112.1791\n",
      "Epoch 42/100\n",
      "808/808 [==============================] - 0s - loss: 142.9322 - val_loss: 110.6159\n",
      "Epoch 43/100\n",
      "808/808 [==============================] - 0s - loss: 141.3125 - val_loss: 110.0932\n",
      "Epoch 44/100\n",
      "808/808 [==============================] - 0s - loss: 135.3025 - val_loss: 109.7531\n",
      "Epoch 45/100\n",
      "808/808 [==============================] - 0s - loss: 139.0961 - val_loss: 110.5549\n",
      "Epoch 46/100\n",
      "808/808 [==============================] - 0s - loss: 139.8776 - val_loss: 108.2969\n",
      "Epoch 47/100\n",
      "808/808 [==============================] - 0s - loss: 136.7304 - val_loss: 113.5132\n",
      "Epoch 48/100\n",
      "808/808 [==============================] - 0s - loss: 127.3299 - val_loss: 106.3025\n",
      "Epoch 49/100\n",
      "808/808 [==============================] - 0s - loss: 136.3339 - val_loss: 108.1835\n",
      "Epoch 50/100\n",
      "808/808 [==============================] - 0s - loss: 133.3990 - val_loss: 103.7366\n",
      "Epoch 51/100\n",
      "808/808 [==============================] - 0s - loss: 129.6637 - val_loss: 106.5759\n",
      "Epoch 52/100\n",
      "808/808 [==============================] - 0s - loss: 127.5254 - val_loss: 104.7675\n",
      "Epoch 53/100\n",
      "808/808 [==============================] - 0s - loss: 132.2351 - val_loss: 103.3879\n",
      "Epoch 54/100\n",
      "808/808 [==============================] - 0s - loss: 134.5150 - val_loss: 103.2043\n",
      "Epoch 55/100\n",
      "808/808 [==============================] - 0s - loss: 126.1098 - val_loss: 101.8478\n",
      "Epoch 56/100\n",
      "808/808 [==============================] - 0s - loss: 117.5494 - val_loss: 101.7829\n",
      "Epoch 57/100\n",
      "808/808 [==============================] - 0s - loss: 133.8056 - val_loss: 101.9528\n",
      "Epoch 58/100\n",
      "808/808 [==============================] - 0s - loss: 125.3172 - val_loss: 100.1262\n",
      "Epoch 59/100\n",
      "808/808 [==============================] - 0s - loss: 120.7315 - val_loss: 101.1850\n",
      "Epoch 60/100\n",
      "808/808 [==============================] - 0s - loss: 122.4761 - val_loss: 99.8698\n",
      "Epoch 61/100\n",
      "808/808 [==============================] - 0s - loss: 125.5269 - val_loss: 99.5905\n",
      "Epoch 62/100\n",
      "808/808 [==============================] - 0s - loss: 115.4527 - val_loss: 98.4324\n",
      "Epoch 63/100\n",
      "808/808 [==============================] - 0s - loss: 126.2173 - val_loss: 99.6028\n",
      "Epoch 64/100\n",
      "808/808 [==============================] - 0s - loss: 120.4664 - val_loss: 97.0634\n",
      "Epoch 65/100\n",
      "808/808 [==============================] - 0s - loss: 119.6387 - val_loss: 98.6210\n",
      "Epoch 66/100\n",
      "808/808 [==============================] - 0s - loss: 118.0745 - val_loss: 96.9664\n",
      "Epoch 67/100\n",
      "808/808 [==============================] - 0s - loss: 112.5888 - val_loss: 93.8096\n",
      "Epoch 68/100\n",
      "808/808 [==============================] - 0s - loss: 114.0672 - val_loss: 97.6500\n",
      "Epoch 69/100\n",
      "808/808 [==============================] - 0s - loss: 114.8260 - val_loss: 95.9619\n",
      "Epoch 70/100\n",
      "808/808 [==============================] - 0s - loss: 110.0272 - val_loss: 96.4171\n",
      "Epoch 71/100\n",
      "808/808 [==============================] - 0s - loss: 113.6112 - val_loss: 96.1166\n",
      "Epoch 72/100\n",
      "808/808 [==============================] - 0s - loss: 112.1138 - val_loss: 95.7657\n",
      "Epoch 73/100\n",
      "808/808 [==============================] - 0s - loss: 110.3059 - val_loss: 95.1692\n",
      "Epoch 74/100\n",
      "808/808 [==============================] - 0s - loss: 117.9345 - val_loss: 97.0277\n",
      "Epoch 75/100\n",
      "808/808 [==============================] - 0s - loss: 114.5213 - val_loss: 96.4393\n",
      "Epoch 76/100\n",
      "808/808 [==============================] - 0s - loss: 115.8963 - val_loss: 96.6044\n",
      "Epoch 77/100\n",
      "808/808 [==============================] - 0s - loss: 114.3094 - val_loss: 95.6948\n",
      "Epoch 78/100\n",
      "808/808 [==============================] - 0s - loss: 105.7911 - val_loss: 95.0974\n",
      "Epoch 79/100\n",
      "808/808 [==============================] - 0s - loss: 109.5286 - val_loss: 93.8298\n",
      "Epoch 80/100\n",
      "808/808 [==============================] - 0s - loss: 109.3982 - val_loss: 92.4208\n",
      "Epoch 81/100\n",
      "808/808 [==============================] - 0s - loss: 108.3238 - val_loss: 92.8237\n",
      "Epoch 82/100\n",
      "808/808 [==============================] - 0s - loss: 112.9447 - val_loss: 92.9711\n",
      "Epoch 83/100\n",
      "808/808 [==============================] - 0s - loss: 113.8448 - val_loss: 94.2258\n",
      "Epoch 84/100\n",
      "808/808 [==============================] - 0s - loss: 106.4842 - val_loss: 92.0957\n",
      "Epoch 85/100\n",
      "808/808 [==============================] - 0s - loss: 103.4633 - val_loss: 90.7264\n",
      "Epoch 86/100\n",
      "808/808 [==============================] - 0s - loss: 109.3379 - val_loss: 90.5027\n",
      "Epoch 87/100\n",
      "808/808 [==============================] - 0s - loss: 102.7414 - val_loss: 91.6341\n",
      "Epoch 88/100\n",
      "808/808 [==============================] - 0s - loss: 109.2562 - val_loss: 91.1635\n",
      "Epoch 89/100\n",
      "808/808 [==============================] - 0s - loss: 104.1715 - val_loss: 89.5310\n",
      "Epoch 90/100\n",
      "808/808 [==============================] - 0s - loss: 103.7760 - val_loss: 93.5970\n",
      "Epoch 91/100\n",
      "808/808 [==============================] - 0s - loss: 108.4033 - val_loss: 88.1100\n",
      "Epoch 92/100\n",
      "808/808 [==============================] - 0s - loss: 99.9842 - val_loss: 90.4759\n",
      "Epoch 93/100\n",
      "808/808 [==============================] - 0s - loss: 105.4798 - val_loss: 90.1501\n",
      "Epoch 94/100\n",
      "808/808 [==============================] - 0s - loss: 98.9645 - val_loss: 91.2668\n",
      "Epoch 95/100\n",
      "808/808 [==============================] - 0s - loss: 104.9930 - val_loss: 91.5581\n",
      "Epoch 96/100\n",
      "808/808 [==============================] - 0s - loss: 106.6334 - val_loss: 87.1761\n",
      "Epoch 97/100\n",
      "808/808 [==============================] - 0s - loss: 99.7803 - val_loss: 87.2458\n",
      "Epoch 98/100\n",
      "808/808 [==============================] - 0s - loss: 99.8949 - val_loss: 87.5604\n",
      "Epoch 99/100\n",
      "808/808 [==============================] - 0s - loss: 103.8974 - val_loss: 88.7255\n",
      "Epoch 100/100\n",
      "808/808 [==============================] - 0s - loss: 100.9595 - val_loss: 86.9961\n",
      "Fold 4\n",
      "Train on 809 samples, validate on 203 samples\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 0s - loss: 4709.8958 - val_loss: 4328.4418\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 0s - loss: 4545.6195 - val_loss: 4042.9103\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 0s - loss: 4086.0087 - val_loss: 3352.0183\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 0s - loss: 3159.1504 - val_loss: 2204.0706\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 0s - loss: 1933.6068 - val_loss: 1177.4936\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 0s - loss: 1158.5693 - val_loss: 775.4289\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 0s - loss: 814.4858 - val_loss: 546.1533\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 0s - loss: 658.9352 - val_loss: 422.5983\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 0s - loss: 527.6782 - val_loss: 345.6455\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 0s - loss: 434.3515 - val_loss: 300.5253\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 0s - loss: 382.2034 - val_loss: 272.1679\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 0s - loss: 363.7057 - val_loss: 250.9049\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 0s - loss: 333.2821 - val_loss: 236.5287\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 0s - loss: 322.6051 - val_loss: 223.4058\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 0s - loss: 301.9060 - val_loss: 213.4477\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 0s - loss: 303.2105 - val_loss: 205.9170\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 0s - loss: 281.8691 - val_loss: 196.8300\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 0s - loss: 269.2022 - val_loss: 190.5836\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 0s - loss: 269.3947 - val_loss: 181.6825\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 0s - loss: 266.2401 - val_loss: 172.6825\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 0s - loss: 246.9815 - val_loss: 167.5511\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 0s - loss: 237.9934 - val_loss: 156.6410\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 0s - loss: 227.8983 - val_loss: 147.0431\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 0s - loss: 209.9623 - val_loss: 137.0303\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 0s - loss: 202.8689 - val_loss: 129.8829\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 0s - loss: 208.6081 - val_loss: 120.9383\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 0s - loss: 193.0405 - val_loss: 115.2023\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 0s - loss: 185.4166 - val_loss: 111.6078\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 0s - loss: 170.4553 - val_loss: 106.3502\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 0s - loss: 178.5359 - val_loss: 104.9428\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 0s - loss: 179.0472 - val_loss: 102.0599\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 0s - loss: 167.9920 - val_loss: 100.9409\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 0s - loss: 167.4525 - val_loss: 99.1543\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 0s - loss: 159.6613 - val_loss: 96.1683\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 0s - loss: 165.8499 - val_loss: 95.2958\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 0s - loss: 159.8605 - val_loss: 95.6085\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 0s - loss: 151.0703 - val_loss: 95.0255\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 0s - loss: 155.7174 - val_loss: 95.6901\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 0s - loss: 157.5469 - val_loss: 91.5722\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 0s - loss: 158.9979 - val_loss: 91.4098\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 0s - loss: 153.6677 - val_loss: 90.0183\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 0s - loss: 153.9337 - val_loss: 89.8406\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 0s - loss: 152.8657 - val_loss: 90.2600\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 0s - loss: 139.5044 - val_loss: 87.2658\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 0s - loss: 150.2569 - val_loss: 89.1828\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 0s - loss: 144.8902 - val_loss: 86.7195\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 0s - loss: 149.2905 - val_loss: 86.4434\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 0s - loss: 140.9986 - val_loss: 84.3948\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 0s - loss: 137.5397 - val_loss: 83.8774\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 0s - loss: 136.6743 - val_loss: 83.6312\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 0s - loss: 143.9925 - val_loss: 82.7782\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 0s - loss: 129.7636 - val_loss: 84.0863\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 0s - loss: 143.0705 - val_loss: 81.8828\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 0s - loss: 132.9166 - val_loss: 81.3693\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 0s - loss: 131.1698 - val_loss: 82.9902\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 0s - loss: 133.0080 - val_loss: 81.3472\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 0s - loss: 131.6749 - val_loss: 80.6923\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 0s - loss: 136.5414 - val_loss: 81.2433\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 0s - loss: 132.1188 - val_loss: 80.9572\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 0s - loss: 135.4400 - val_loss: 81.4201\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 0s - loss: 131.5834 - val_loss: 78.9112\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 0s - loss: 127.4339 - val_loss: 79.3915\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 0s - loss: 128.6503 - val_loss: 78.1683\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 0s - loss: 120.3752 - val_loss: 76.9014\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 0s - loss: 124.0933 - val_loss: 78.7252\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 0s - loss: 120.8820 - val_loss: 77.5295\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 0s - loss: 126.7966 - val_loss: 76.5681\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 0s - loss: 126.2810 - val_loss: 77.4910\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 0s - loss: 125.8501 - val_loss: 77.7882\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 0s - loss: 116.1419 - val_loss: 77.6936\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 0s - loss: 121.0682 - val_loss: 78.2609\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 0s - loss: 114.9232 - val_loss: 75.1610\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 0s - loss: 116.2283 - val_loss: 75.1190\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 0s - loss: 111.3659 - val_loss: 79.8599\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 0s - loss: 119.6955 - val_loss: 74.7567\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 0s - loss: 115.8641 - val_loss: 75.0045\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 0s - loss: 111.8685 - val_loss: 73.6494\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 0s - loss: 122.6598 - val_loss: 73.7541\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 0s - loss: 119.0854 - val_loss: 73.8401\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 0s - loss: 112.8904 - val_loss: 74.2809\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 0s - loss: 113.3239 - val_loss: 73.5218\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 0s - loss: 112.6807 - val_loss: 72.5215\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 0s - loss: 111.9385 - val_loss: 72.4924\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 0s - loss: 115.9394 - val_loss: 72.1265\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 0s - loss: 118.2744 - val_loss: 72.4520\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 0s - loss: 111.1091 - val_loss: 71.7772\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 0s - loss: 112.8202 - val_loss: 72.5548\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 0s - loss: 117.3933 - val_loss: 70.9232\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 0s - loss: 113.7544 - val_loss: 72.8804\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 0s - loss: 112.2343 - val_loss: 71.9317\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 0s - loss: 112.5332 - val_loss: 70.8824\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 0s - loss: 108.3940 - val_loss: 72.5073\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 0s - loss: 111.7654 - val_loss: 69.6693\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 0s - loss: 112.1406 - val_loss: 71.5999\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 0s - loss: 106.9034 - val_loss: 69.7198\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 0s - loss: 106.2016 - val_loss: 71.1750\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 0s - loss: 112.1195 - val_loss: 69.6313\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 0s - loss: 105.4604 - val_loss: 70.6459\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 0s - loss: 101.3325 - val_loss: 69.5780\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 0s - loss: 109.4718 - val_loss: 68.1884\n",
      "1 <function regression at 0x0000016E1020A268>\n",
      "2 <bound method SupervisedFloatMixin.fit of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "          weights='uniform')>\n",
      "3 <bound method DecisionTreeRegressor.fit of DecisionTreeRegressor(criterion='mse', max_depth=7, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')>\n",
      "4 <bound method DecisionTreeRegressor.fit of ExtraTreeRegressor(criterion='mse', max_depth=7, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j, clf in enumerate(clfs):    \n",
    "    print(j, clf)\n",
    "    blend_test_j = np.zeros(shape=(5, len(testX),2))\n",
    "    for i, (train_index, test_index) in enumerate(skf):\n",
    "        print(\"Fold\", i)   \n",
    "\n",
    "        X_train = trainX[train_index]\n",
    "        y_train = trainY[train_index]\n",
    "        X_test = trainX[test_index]\n",
    "        y_test = trainY[test_index]\n",
    "\n",
    "    #     model1 = rr.train_model(X_train,y_train)\n",
    "        model = clf(X_train,y_train)\n",
    "        blend_train[j, test_index, :] =  model.predict(X_test)\n",
    "        blend_test_j[:,:,i] =   model.predict(testX)\n",
    "        \n",
    "\n",
    "    blend_test[:,:,j] = blend_test_j.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 49.99036026,   0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 34.67944336,   0.        ,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_train[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-0851c735d657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mneig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mneig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblend_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0me3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    739\u001b[0m         \"\"\"\n\u001b[0;32m    740\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\software\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 405\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# stacking model 3\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neig = KNeighborsRegressor(n_neighbors=4)\n",
    "neig.fit(blend_train,trainY)\n",
    "pred3 = neig.predict(blend_test)\n",
    "e3, a3 = accuracy(pred3, test_y)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]]]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((3,2,5))\n",
    "print(a)\n",
    "print(a[:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 9],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array([[2,0],[1,9],[3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
